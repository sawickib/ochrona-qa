%\documentclass[]{exam}
\documentclass[answers,11pt]{exam}

%\renewcommand{\familydefault}{\sfdefault}
\usepackage[utf8]{inputenc}

\usepackage[polish]{babel}
\usepackage{polski}

\renewcommand{\solutiontitle}{}
%\renewcommand{\solutiontitle}{\noindent\textbf{Odpowiedź:} }

\newcommand{\fixit}{\textit{(Dobrze, ale do lekkiej poprawki)} }

\cfoot[]{}
\rfoot[]{strona \thepage}

\title{Ochrona danych w systemach informatycznych \\ \vspace{0.5cm} \large{niepełny zbiór pytań i przykładowych odpowiedzi}}
\author{Bartosz Sawicki \\ \small{Wydział Elektryczny, Politechnika Warszawska}}

\begin{document}

\maketitle

\noindent\textbf{Słowo wstępu}

Niniejszy zbiór pytań i odpowiedzi obejmuje zdecydowaną większość materiału poruszanego w ramach wykładu ,,Ochrona danych w systemach informatycznych'' na drugim roku studiów na kierunku Informatyka na Wydziale Elektrycznym Politechniki Warszawskiej. Lista pytań jest dosyć rozległa jednak nie wyczerpuje całkowicie wszystkich tematów, dlatego nie należy traktować jej jako jedyne źródło wiedzy. Tym bardziej, że prezentowane teksty nie wyjaśniają opisywanych tematów, a są po prostu krótkimi, przykładowymi odpowiedziami na pytania egzaminacyjne. Przygotowując się do egzaminu trzeba sięgnąć do slajdów i podanej literatury.

Przy opracowywaniu tego zbioru wykorzystywałem wiele źródeł o uznanej wiarygodności, ale specjalne podziękowania leżą się również wielu studentom, którzy udostępnili swoje notatki. Mam nadzieję, że w ten sposób tekst stał się bardziej przystępny. Zapraszam do przesyłania poprawek i uzupełnień tego opracowania.

Źródło dokumentu: \verb+https://github.com/sawickib/ochrona-qa+

\vspace{0.5cm}\hspace*{10cm}\textit{Bartosz.Sawicki@ee.pw.edu.pl}

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%
\section{Kryptografia}

\subsection{Kryptografia klasyczna}

\begin{questions}

\question Omów trzy wybrane zasady dobrego systemu kryptograficznego podane przez Kerkhoffsa.
\begin{solution}
\begin{itemize}
\item Utajniony powinien być klucz, a nie budowa maszyny szyfrującej - w ten sposób system nie zostanie skompromitowany gdy wróg przechwyci maszynę. Wystarczy tylko zmienić klucz.
\item System powinien być łatwy w użyciu - w przeciwnym razie użytkownicy będą unikali stosowania go, tym samy narażając dane na niebezpieczeństwo.
\item Liczy się praktyczna, a nie bezwzględna odporność systemu - dlatego należy zawsze uwzględniać rolę jaką pełni zabezpieczenie. Do ochrony danych wartych 1000zł, nie warto stosować systemów za miliony.
\end{itemize}
\end{solution}

\question Wymień zasady Kerkhoffsa
\begin{solution}
\begin{enumerate}
\item System praktycznie nie do złamania.
\item Utajniony jest klucz, a nie sama budowa maszyny. 
\item Klucz powinien być łatwy do zapamiętania.
\item Kryptogram łatwy do przekazania.
\item Maszyna szyfrująca łatwa do przenoszenia. 
\item System łatwy w użyciu.
\end{enumerate}
\end{solution}

\question Omów najważniejszą zasadę Kerkhoffsa.
\begin{solution}
\emph{Utajniony powinien być klucz, a nie budowa maszyny szyfrującej.} W ten sposób bezpieczeństwo systemu nie będzie zagrożone nawet gdy wróg przechwyci maszynę. Wystarczy tylko zmienić klucz. Zasada ta również stosowana jest przy systemach informatycznych jako argument za ujawnianiem kodu algorytmów szyfrujących.
\end{solution}

\question Przedstaw metodę projektowania dobrego szyfru homofonicznego.
\begin{solution}
Podstawą działania szyfru homofonicznego jest podstawienie jeden do wielu, czyli jednemu symbolowi tekstu jawnego może odpowiadać wiele symboli kryptogramu. Celem tego szyfru jest spłaszczenie histogramu kryptogramu w ten sposób, że najczęściej występującym znakom w tekście jawnym przypisana jest największa liczba homofonów. Oczywiście taka operacja wymaga aby liczba symboli występujących w kryptogramie była wyraźnie większa niż symboli tekstu jawnego.
\end{solution}

\question Jakie algorytmy podatne są na kryptoanalizę statystyczno-lingwistyczną?
\begin{solution}
Zasadniczo większość algorytmów historycznych miało problem ze zniekształcaniem statystycznych cech tekstu napisanego w języku naturalnym. Każdy język charakteryzuje się pewną częstotliwością występowania poszczególnych liter. Dysponując dużą próbką tekstu możemy z dużą pewnością określić jakie znaki odpowiadają jakim literom. Najbardziej podatne na tego typu atak są algorytmu jednoznakowe, monoalfabetyczne (np. alg. Cezara). Algorytmy polialfabetyczne są lepsze pod tym względem. 
\end{solution}

\question Na czym polega algorytm autokey?
\begin{solution}
Algorytm autokey jest rozszerzeniem algorytmu Vigenere'a. Polega on na uzupełnieniu klucza przy pomocy tekstu jawnego. W ten sposób unikamy ciągłego powtarzania hasła, co ułatwiłoby atak oparty na częstotliwości znaków. 
\end{solution}

\question Opisz zasadę algorytmów polifonicznych?
\begin{solution}
Algorytmy polifoniczne, to rodzaj szyfrów przez podstawienie, w których kilka znaków z alfabetu tekstu jawnego jest przekształcanych w ten jeden, ten sam znak kryptogramu. Takie przekształcenie jest nie jednoznaczne w rozszyfrowaniu. Z tego powodu algorytmy polifoniczne są odporne na kryptoanalizę, ale jednocześnie trudne w stosowaniu.
\end{solution}

\question Omów systematykę klasycznych algorytmów szyfrowania przez podstawienie?
\begin{solution}
Jest kilka klasyfikacji algorytmów tego typu. Możemy wydzielić algorytmy jednoznakowe, w których niezależnie szyfrowane są poszczególe litery tekstu jawnego, lub algorytmy poligramowe (jednoczesne szyfrowanie kilku znaków). 
Drugi podział opiera się na tym, czy jest jeden słownik/alfabet tłumaczący (monoalfabetyczne), czy też jest ich wiele (polialfabetyczne). 
\end{solution}

\question Przedstaw wybrany algorytm szyfrowania polialfabetyczny.
\begin{solution}
Szyfry polialfabetyczne są algorytmami szyfrującymi przez podstawienie, w którym wykorzystywanych jest wiele alfabetów tłumaczących kolejne znaki tekstu jawnego na kryptogram. Przykładem może być algorytm Vigenere'a. Jest to rozszerzenie algorytmu Cezara w taki sposób, że kolejne znaki  ($p_i$) szyfrowane są z innym przesunięciem wynikającym z odpowiedniego symbolu klucza ($k_i$).
\begin{equation}
c_i = p_i + k_i \pmod{26}
\end{equation}
\end{solution}

\question Omów szyfr afiniczny.
\begin{solution}
Szyfr afiniczny to algorytm monoalfabetyczny podstawieniowy. Operacja szyfrowania definiowana jest przez równanie matematyczne $E(x) = ax + b \pmod{26}$. Przy czym, żeby szyfrowanie było odwracane wymagane jest, żeby $a$ było względnie pierwsze z $26$. Odszyfrowanie realizowane jest przez $D(x) = a^{-1}(x-b) \pmod{26}$.
\end{solution}


\question Przedstaw wybrany algorytm szyfrowania monoalfabetyczny.
\begin{solution}
Przykładem algorytmu monoalfabetycznego jest szyfr ROT-13. Polega on na zastąpieniu każdej litery tekstu jawnego poprzez literę przesuniętą cyklicznie o 13 znaków w alfabecie. W podstawowym alfabecie ASCII jest 26 znaków, a więc ROT-13 ma tą zaletę, że zaszyfrowanie kryptogramu daje w wyniku tekst jawny.
\end{solution}

\question Przedstaw wybrany algorytm szyfrowania poligramowy.
\begin{solution}
W algorytmach poligramowych szyfrowane jest więcej niż jeden symbol jednocześnie. Przykładem może być szyfr Playfair, w którym w kratkę o rozmiarze 5x5 wpisywane jest hasło uzupełnione pozostałymi literami alfabetu. Na podstawie położenia liter poszczególnych bigramów (kolejnych dwóch znaków tekstu jawnego) wybiera się położenie znaków kryptogramu. Jeżeli litery znajdują się w tym samym rzędzie (kolumnie), to wybieramy znaki leżące po prawej (poniżej). W innej sytuacji wybieramy znaki znajdujące się po przekątnej od liter bigramu.  
\end{solution}


\end{questions}

\subsection{Kryptografia współczesna}

\begin{questions}

\question Dlaczego funkcja XOR jest tak często stosowana w kryptografii?
\begin{solution}
Funkcja XOR jest najprostszą operacją logiczną, która może zapewnić szyfrowanie i deszyfrowanie przy pomocy tego samego klucza. Symetryczne algorytmy strumieniowe opierają się na bramce XOR.
\end{solution}

\question Omów algorytm szyfrowania one-time pad?
\begin{solution}
Algorytm OTP w swoich założeniach zbliża się do algorytmu doskonałego, czyli takiego, który ma udowodnioną odporność na wszelkiego typy ataki. Podstawowym założeniem OTP jest wykorzystanie losowego klucza. Klucz w OTP musi spełniać szereg warunków:
\begin{itemize}
\item klucz musi być tak długi jak tekst jawny,
\item klucz musi być ciągiem doskonale losowym,
\item nigdy nie wolno wykorzystać dwa razy tego samego klucza.
\end{itemize}
Nie trudno zauważyć, że OTP jest mało praktyczny w zwykłych zastosowaniach. Używa się go do zastosowań specjalnych, a także jego elementy można znaleźć w innych algorytmach.
\end{solution}

\question Ile wynosi entropia dobrego kryptogramu? Odpowiedź uzasadnij.
\begin{solution}
Dobry kryptogram powinien nie nieść żadnej informacji statystycznej, czyli przypominać biały szum. Entropia jest sumą logarytmów z prawdopodobieństwa poszczególnych wartości.
\begin{equation}
H(x)= - \sum_{i=1}^n p(i) \ log_2 p(i)
\end{equation}
W idealnym szumie prawdopodobieństwa są jednakowe, a więc entropia będzie miała maksymalną wartość. 
\end{solution}

\question Oceń maksymalną entropię hasła składającego się z 8 cyfr.
\begin{solution}
Przy założeniu, że wszystkie możliwości są równie prawdopodobne entropia wynosi:
\begin{equation}
H = 8 * log_2 10 = 8 * 3.32 = 26.6 bits
\end{equation}
\end{solution}

\question Oblicz entropię ciągu ,,bdabbabc''.
\begin{solution}
Zgodnie ze wzorem:
\begin{equation}
H = - \sum_{i=1}^n p_i \ log_2 p_i
\end{equation}
Obliczamy prawdopodobieństwo wystąpienia w ciągu każdej z liter jako iloraz liczby wystąpień danej litery przez długość całego ciągu, np. $ p(b) = 4/8 = 0.5 $. Podstawiamy wartości do wzoru ogólnego i otrzymujemy entropię.
\begin{equation}
H = - ( 0.25 * log_2 0.25 + 0.5 * log_2 0.5 + 0.125 * log_2 0.125 + 0.125 * log_2 0.125 ]
\end{equation}
\begin{equation}
H = -((-0.5)+(-0.5)+(-0.375)+(-0.375))
\end{equation}
\begin{equation}
H = 1.75
\end{equation}
\end{solution}

\question Określ relację pomiędzy maksymalna liczba prób ataku brute force na hasło, a jego maksymalną entropią.
\begin{solution}
Maksymalna liczba prób jest równa $2^H$, gdzie H jest entropia w bitach. Na przykład dla czterocyfrowego PINu $H = 4*3.32 = 13.28 $, a liczba prób wynosi $ 2^{13.28} = 9946 \approx 10000$ .
\end{solution}

\question Przedstaw podstawową technikę wykorzystania bramki XOR w konstrukcji szyfru.
\begin{solution}
Bramka logiczna XOR stanowi podstawę algorytmów szyfrowania strumieniowego. Cała technika polega na połączeniu operatorem XOR strumienia bitów tekstu jawnego ze strumieniem klucza. Dzięki cechom tej bramki, ten sam układ może być również wykorzystywany do deszyfrowania (XOR pomiędzy kryptogramem a kluczem). 
\end{solution}

\question Udowodnij, że dwukrotne szyfrowania bramką XOR daje z powrotem tekst jawny.
\begin{solution}
Wiedząc, że operacja XOR ($\oplus$) posiada następujące cechy: $\forall_{x,y,z} (x \oplus y) \oplus z = x \oplus (y \oplus z) $(łączność), $x \oplus x = 0$, oraz $x \oplus 0 = x$, można pokazać, że dwukrotne XORowanie z kluczem daje tekst jawny:
\begin{equation}
c = p \oplus k 
\end{equation}
\begin{equation}
c \oplus k = (p \oplus k) \oplus k = p \oplus (k \oplus k ) = p \oplus 0 = p 
\end{equation}
\end{solution}

\question Omów podstawowe problemy prawne związane ze stosowaniem silnej kryptografii.
\begin{solution}
Współczesna kryptografia dostarcza bardzo silnych narzędzi ochrony poufności danych. Rodzi to pewnego rodzaju problemy społeczne i prawne, albowiem przestępcy mogą stosunkowo łatwo ukrywać dowody, albo komunikować się w sposób całkowicie poufny. Z tego też powodu w niektórych krajach silna kryptografia podlega podobnym regulacjom prawnym jak broń. Jednak z drugiej strony wraz z rosnącym znaczeniem systemów IT, ich skuteczna ochrona staje się coraz ważniejsza, a co za tym idzie rośnie potrzeba silnej kryptografii.
\end{solution}

\question Przedstaw koncepcję szyfrów homomorficznych.
\begin{solution}
Homomorficzność jest cechą algorytmów szyfrujących, która umożliwia wykonywanie pewnych operacji na kryptogramie bez jego odszyfrowywania. Następnie wynik takich obliczeń może być  odszyfrowany. Koncepcja szyfrów homomorficznych jest atrakcyjna, bowiem pozwala na zbudowanie zewnętrznego systemu przetwarzania dla wrażliwych danych. Istnieją pierwsze prototypowe algorytmy tego typu, jednak są one bardzo kosztowne obliczeniowo.
\end{solution}

\question Wyjaśnij dlaczego atak 'brute force' na algorytm szyfrowania OTP nie jest skuteczny?
\begin{solution}
Czysto teoretycznie algorytm OTP \textbf{jest} podatny na atak brute-force; sęk w tym, że przeprowadzenie takiego ataku przy użyciu wszystkich możliwych kluczy da nam wszystkie możliwe wiadomości. Problemem będzie zatem nie złamanie klucza, ale wyłowienie oryginalnej wiadomości. A przy założeniu rzeczywistej losowości klucza każda z odszyfrowanych wersji jest jednakowo prawdopodobna.
\end{solution}


\end{questions}

\subsection{Liczby losowe}
\begin{questions}

\question Omów zasadę działania generatora liczb pseudolosowych opartego na LFSR.
\begin{solution}
LFSR oznacza z angielskiego ,,liniowy rejestr przesuwny ze sprzężeniem zwrotnym'' (ang. linear feedback shift register). Działa on na zasadzie kombinacji liniowej wybranych elementów rejestru, które tworzą nowe dane zasilające rejestr pętlą zwrotną. Ten prosty schemat powoduje, że układ ten jest prosty do realizacji i może działać z wielką szybkością. Wadą jest jednak niska jakość generowanego ciągu pseudolosowego. W praktyce generatory tego typu nie nadają się do zastosowań kryptograficznych.
\end{solution}

\question Przedstaw pięć zastosowań liczb losowych w kryptografii.
\begin{solution}
Liczby losowe to bardzo ważny element wielu algorytmów. Na przykład:
\begin{itemize}
\item Wektor inicjalizujący IV w trybie CBC.
\item Liczby $p$ i $q$ wykorzystywane podczas tworzenia kluczy RSA.
\item Element wyzwania przy algorytmach uwierzytelniania typu wyzwanie odpowiedź.
\item Sól dla metod przechowywania haseł.
\item Podstawa algorytmu OTP.
\end{itemize}
\end{solution}

\question Wyjaśnij zasadę działania generatorów prawdziwych liczb losowych.
\begin{solution}
Prawdziwe liczby losowe nie mogą być wygenerowane przez komputery, które działają w sposób ściśle określony, deterministyczny. Źródłem danych losowych może być tylko proces fizyczny ze świata realnego, którego złożoność jest niemożliwa do dokładnego odtworzenia. Dobrymi generatorami są zjawiska ze skali makro (rzut kostką, ruletka, itp.) a także zjawiska na poziomie mikro (szum termiczny, efekty fotoelektryczne, itp.)
\end{solution}

\question Scharakteryzuj bezpieczne generatory liczb losowych.
\begin{solution}
Bezpieczne generatory liczb losowych (eng. CSPRNG) stanowią szczególną klasę generatorów pseudolosowych. Aby generator mógł być uznany za CSPRNG musi przejść \textit{test następnego bitu} - nie może istnieć efektywny algorytm, który potrafi przewidzieć kolejny generowany bit z prawdopodobieństwem większym niż $0.5$. Opierają się na algorytmach kryptograficznych (DES, RSA, MD5, SHA) lub są zaprojektowane specjalne do takich celów (Yarrow, Blum Blum Shub), które na podstawie ziarna tworzą ciąg liczb losowych. Przy tworzeniu ziarna generator korzysta z możliwie nieprzewidywalnego źródła danych np. ,,machanie'' myszką po ekranie przez określony czas, zmiany temperatury procesora/płyty głównej, parametry pracy dysku. Generatory te mogą być bezpiecznie używane w kryptografii. 
\end{solution}


\question Wyjaśnij w jaki sposób komputer będący deterministyczną maszyną stanów może dokonać aktu losowania.
\begin{solution}
\fixit
1) Komputer będący deterministyczną maszyną stanów może dokonać aktu losowania na 2 sposoby zależnie od tego jakich liczb losowych potrzebujemy. W przypadku prawdziwych liczb losowych odbywa się to poprzez pobieranie danych z nieprzewidywalnego źródła. Komputer wykorzystuje źródło takie jak np. miernik stężenia promieniowania radioaktywnego (takie rozwiązania wymagają przekazywania danych do komputera z zewnętrznych urządzeń) lub wewnętrzne źródło jakim jest jego procesor, jako źródła entropii. Następnie komputer jest w stanie wygenerować prawdziwe liczby losowe, ponieważ tego typu zdarzenia generują nieprzewidywalne dla nikogo wyniki (ciężko jest przewidzieć ile dokładnie w ciągu następnych 100ms nasz procesor odbierze i wyśle pakietów lub jak będzie zmieniała się temperatura procesora uwzględniając 10 miejsc po przecinku). W przypadku, gdy potrzebne nam liczby nie muszą być prawdziwie losowe, możemy użyć prostych algorytmów losowania liczb pseudolosowych z użyciem ziarna ("seed"), jednakże należy pamiętać, że takie rozwiązanie w przypadku użycia takiego samego ziarenka np. 10 na wszystkich maszynach, na których zostanie odpalona, da dokładnie takie same wylosowane liczby, aby uniknąć tego problemu należy dobierać unikalne ziarno, bardzo często jest to liczba sekund, która minęła od 1 stycznia 1970 roku do chwili uruchomienia programu, sprawia to, że z każdym uruchomieniem programu mamy inne ziarenko, a co za tym idzie inne liczby pseudolosowe. 

2) Komputer sam z siebie nigdy nie wygeneruje niczego losowego. Każdy algorytm jest funkcją przekształcającą bieżący stan komputera w następny (przekształca zbiór skończony w siebie). Każda taka funkcja po pewnej liczbie iteracji wpadnie w cykl, a co za tym idzie nigdy nie uzyskamy losowości. Komputer jest w stanie wytworzyć coś, co wygląda jak losowe (patrz wyżej - generatory liczb pseudolosowych). Jednak komputer to też dyski, urządzenia wejścia/wyjścia, szumy i zakłócenia. To właśnie szumów i zakłóceń możemy użyć do wykonania aktu losowania.
\end{solution}

\question Ile wynosi entropia ciągu doskonale losowego? Odpowiedź uzasadnij.
\begin{solution}
W ciągu doskonale losowym rozkład prawdopodobieństwa jest jednostajny, tak więc entropię wyznacza się ze wzoru:
\begin{equation}
H = n * log_2 N
\end{equation}

Gdzie N to moc zbioru możliwych znaków, zaś n oznacza długość ciągu doskonale losowego.
\end{solution}
\end{questions}

\subsection{Algorytmy symetryczne strumieniowe}
\begin{questions}

\question Omów algorytm RC4.
\begin{solution}
RC4 (zwany również ARC4 albo ARCFOUR) jest popularnym szyfrem strumieniowym. Używany jest w protokołach, takich jak SSL oraz WEP. Szyfr RC4 nie jest bezpiecznym szyfrem i znane są sposoby ataku w związku z tym algorytm nie jest zalecany do używania w nowych systemach.

RC4 jak wszystkie algorytmy strumieniowe generuje strumień klucza, który następnie jest XORowany ze strumieniem tekstu jawnego. W wyniku tej operacji powstaje kryptogram.

Działanie RC4 opiera się na 256 bajtowej tablicy $S$, zawierającej wszystkie wartości 0-255. Tablica ta jest inicjowana na podstawie hasła, a następnie przy pomocy prostych operacji w pętli można z niej generować nieskończony strumień klucza. 
\end{solution}

\question Omów algorytm szyfrowania A5/1.
\begin{solution}
Algorytm A5/1 to najbardziej popularna metoda zabezpieczenia poufności w komunikacji w sieci GSM. Jest to szyfr strumieniowy oparty na trzech rejestrach liniowych ze sprzężeniem zwrotnym (LSFR). Podstawowa długość klucza wynosi 64 bity, chociaż w praktyce jest mniejsza. Pokazano wiele wydajnych ataków na ten algorytm, a więc nie może być uważany za bezpieczny. Następcą A5/1 jest blokowy algorytm A5/3 wykorzystywany w sieciach G3.
\end{solution}

\end{questions}



\subsection{Algorytmy symetryczne blokowe}
\begin{questions}

\question Na czym polega ECB i czym różni się do CBC.
\begin{solution}
ECB i CBC to dwa najprostsze tryby pracy algorytmów blokowych. W trybie ECB tekst jawny dzielony jest na fragmenty o wielkości bloku i następnie każdy fragment jest niezależnie szyfrowany. W trybie CBC kolejne bloki są ze sobą kaskadowo połączone w ten sposób, że wynik szyfrowania z jednego bloku jest XORowany z następnym blokiem tekstu jawnego. Należy pamiętać, że ECB jest znacznie słabszą metodą, która w praktyce nie powinna być stosowana.
\end{solution}

\question Scharakteryzuj algorytm DES.
\begin{solution}
DES (ang. Data Encryption Standard) to jeden z pierwszych popularnych algorytmów szyfrujący. Od 1979 roku został zatwierdzony w USA jako zalecany do szyfrowania powszechnego. Algorytm operuje na 64 bitowych blokach, które przy pomocy prostych operacji przekształcane są w 16 rundach. Wykorzystywany jest 56 bitowy klucz (64 bity minus 8 bitów kontroli parzystości). Dzisiaj DES nie powinien być już stosowany ze względu na długość klucza. Zaletą DES jest to, że przez wiele lat został dobrze przebadany - dlatego stosowane są rozszerzenia zapewniające dłuższy klucz, np. 3DES, DESX.
\end{solution}

\question Wyjaśnij rolę i budowę elementu S-box.
\begin{solution}
S-box jest kluczowym elementem algorytmów szyfrowania symetrycznego. Jego rola polega na przekształceniu $m$ bitów wejścia w $n$ wyjścia. Operacja opiera się na tablicy, w której bity wejścia określają położenie komórki zawierającej bity wejścia. Poprawne skonstruowanie takiej tablicy jest zadaniem trudnym, dlatego też korzysta się ze zdefiniowanych S-boxów. W przypadku algorytmu DES: S-box ma wymiar (4x16), a dla AES (16x16). 
\end{solution}

\question Opisz zasadę działania S-boxów w algorytmie DES.
\begin{solution}
S-box dla algorytmu DES, to tablica o wymiarach 4x16, która pozwala na przekształcenie 6 bitów wejścia na 4 bity wyjściowe. Dwa zewnętrze bity wejścia tworzą numer wiersza, a cztery wewnętrzne bity opisują numer kolumny. Określona w ten sposób komórka tablicy daje ciąg wyjściowy. W algorytmie DES używanych jest osiem precyzyjnie zdefiniowanych S-boxów. Wszystkie one dobrane są tak, aby inicjować efekt lawinowy, to znaczy zmiana jednego bitu na wejściu skutkuje zmianą co najmniej dwóch bitów na wyjściu.
\end{solution}

\question Scharakteryzuj algorytm AES.
\begin{solution}
Algorytm AES to współcześnie polecany symetryczny szyfr blokowy. Został zatwierdzony do użycia w roku 2001 i zastąpił wysłużony algorytm DES. Długość bloku w AES wynosi 128 bitów, a standard dopuszcza trzy długości kluczy: 128, 192 i 256 bitów. Budowa algorytmu opiera się na powtarzanych wielokrotnie prostych operacjach podstawienia i permutacji. 
\end{solution}

\question Pokaż zasadę działania sieci Feistela.
\begin{solution} 
Sieć Feistela to struktura wykorzystywana w wielu algorytmach szyfrowania blokowego (np. DES). Pozwala na wykorzystanie funkcji jednokierunkowej, przy jednoczesnym zachowaniu możliwości odszyfrowania kryptogramu. Podstawą sieci Feistela jest podział bloku na dwie połówki $L$ i $R$, a następnie zdefiniowanie przekształcenia pomiędzy kolejnymi rundami $i \rightarrow i+1$:
\begin{equation}
L_{i+1} = R_i, \;\; R_{i+1}= L_i \oplus {\rm F}(R_i, K_i).
\end{equation}
Odwrócenie procesu szyfrowania przebiega analogicznie, ale od ostatniej rundy
\begin{equation}
R_{i-1} = L_{i},\;\; L_{i-1} = R_{i} \oplus {\rm F}(L_{i}, K_{i-1}).
\end{equation}
\end{solution}

\question Wykaż, że runda w sieci Feistela jest odwracalna.
\begin{solution} 
Jeżeli zapiszeny szyfrowanie w sieci Feistela jako:
\begin{equation}
L_{i+1} = R_i, \;\; R_{i+1}= L_i \oplus {\rm F}(R_i, K_i),
\end{equation}
a deszyfrowanie jako:
\begin{equation}
R_{i} = L_{i+1},\;\; L_{i} = R_{i+1} \oplus {\rm F}(L_{i+1}, K_{i}),
\end{equation}
to łatwo pokazać, że
\begin{equation}
L_{i} = L_i \oplus {\rm F}(R_i, K_i) \oplus {\rm F}(L_{i+1}, K_{i}),
\end{equation}
co po podstawieniu $L_{i+1} = R_i$ daje
\begin{equation}
L_{i} = L_i \oplus {\rm F}(R_i, K_i) \oplus {\rm F}(R_i, K_{i}).
\end{equation}
Wykorzystując podstawowe cechy operacji XOR ($\oplus$) dostajemy ostatecznie:
\begin{equation}
L_{i} = L_i.
\end{equation}
\end{solution} 


\question Omów różnicę w propagacji błędów pomiędzy trybami ECB i CBC.
\begin{solution}
W trybie ECB każdy blok szyfrowany jest niezależnie, co przekłada się na to, że nie przenoszą się pomiędzy blokami. Inaczej jest w trybie CBC, w którym zakłócenie jednego bitu kryptogramu spowoduje całkowite uszkodzenie dwóch bloków (aktualnego i częściowo następnego). 
\end{solution}

\question Przedstaw tryb CFB
\begin{solution}
CFB jest to tryb pracy algorytmów blokowych. Polega on na sprzężeniu pomiędzy wyjściem z algorytmu blokowego, a jego wejściem. Dopiero wyjście zXORowane z tekstem jawnym daje kryptogram.
Tryb ten może być wykorzystany do stworzenia algorytmu strumieniowego zdolnego do szyfrowania pojedyńczych bitów. 
\end{solution}

\question Wyjaśnij podstawy działania i uzasadnienie dla wykorzystania trybów uwierzytelniająco-szyfrujących.
\begin{solution}
Często występuje potrzeba jednoczesnego zapewnienia poufności i kontroli autentyczności dla wiadomości. W klasycznych rozwiązaniach poufność zapewniana jest poprzez szyfrowanie, a kontrola autentyczności poprzez hashowanie HMAC. Tryby uwierzytelniająco-szyfrujące przeprowadzają te dwie operacje jednocześnie, a więc są znacznie bardziej efektywne, niż przetwarzanie dwuetapowe.
\end{solution}


\question Na czym polega atak meet-in-the-middle?
\begin{solution}
Atak meet-in-the-middle jest wydajnym atakiem na algorytmy, które można rozdzielić na dwie niezależne części (np. 3DES). Atakujący buduje w pamięci bazy wyników szyfrowania dla każdej z części, a następnie szuka w pamięci przecięcia tych zbiorów. Algorytm pozwala znacząco obniżyć liczbę prób, ale kosztem dużych wymagań pamięci.
\end{solution}


\end{questions}



\subsection{Algorytmy funkcji skrótu}
\begin{questions}

\question Na jakie typy ataków podatne są jednokierunkowe funkcje skrótu słabo bezkonfliktowe? Odpowiedź uzasadnij.
\begin{solution}
Słaba bezkonfliktowość do cecha funkcji haszujących, która mówi, że dla danego $x$ trudne jest znalezienie takiego $x'$, że $H(x) = H(x')$.
Przykładem ataku, którego celem jest właśnie znalezienie takiego $x'$ są ataki słownikowe, lub brutalnej siły na hasła.
\end{solution}

\question Jakie warunek musi spełniać funkcja silnie bezkonfliktowa?
\begin{solution}
\fixit
Funkcja silnie bezkonfliktowa wymaga, aby dla każdego x nie było możliwe znalezienie takiego $x'$ różnego od $x$, żeby $f(x) = f(x')$.
\end{solution}

\question Wyjaśnij zasadę działania tablic tęczowych.
\begin{solution}
Tablice tęczowe to struktura zaprojektowana do przeprowadzanie ataków na hasła chronione funkcjami hashującymi. U jej podstaw leży optymalne połączenie czasochłonnych metod brutalnej siły, z pamięciożernymi metodami słownikowymi. Podstawowym elementem tablic tęczowych jest ciąg przekształceń: hash i redukcja. Gdzie redukcja jest przekształceniem tworzącym hasło z jego skrótu. W tablicach tęczowych przechowuje się tylko pierwszy i ostatni element tego ciągu - co czyni metodę znacznie efektywniejszą.
\end{solution}

\question Opisz metody pozwalające na bezpieczne przechowywania haseł w systemie.
\begin{solution}
Najpopularniejsza metoda uwierzytelniania oparta o tajne hasło wymaga, żeby system przechowywał hasło. Potencjalnie taka sytuacja jest niebezpieczna, ze względu na możliwości wykradzenia bazy haseł. Mamy jednak kilka metod, które pozwalają na bezpieczne przechowywanie haseł:
\begin{itemize}
\item przechowujemy hasło przekształcone funkcją hashującą, a nie tekst jawny,
\item używamy losowego modyfikatora (soli), który znacznie utrudnia ataki słownikowe,
\item wielokrotnie hashujemy hasło (np. 1000 razy) w ten sposób utrudniamy ataki brutalnej siły.
\end{itemize}
\end{solution}

\question Omów budowę algorytmu MD5.
\begin{solution}
Algorytm MD5 jest kryptograficzną funkcją haszującą opracowaną w 1991 przez Rivesta. Polega on na wielokrotnym przekształcaniu 128 bitowego rejestru podzielonego na cztery 32 bitowe sekcje na podstawie 512 bitów wejściowego bloku tekstu. Wynikiem operacji jest 128 bitowy hash. Algorytm jest wciąż popularny, mimo, że nie jest on zalecany z powodu znanych ataków.
\end{solution}

\question Omów algorytmy SHA-2.
\begin{solution}
SHA-2 to rodzina algorytmów hashujących. Zawiera ona funkcje generujące hashe od 256 do 512 bitów. Algorytmy SHA-2 są unowocześnionymi wersjami algorytmu SHA-0 i SHA-1, a korzeniami sięgają do MD5. Ich działanie opiera się na serii prostych przekształceń wykorzystujących rejestr 512/1024 bitowy. W 2009 NIST (Narodowy Instytut Standaryzacji i Technologii - amerykańska agencja federalna) ogłosił konkurs na nową wersję algorytmu. Konkurs został zakończony w 2012 roku i jako SHA-3 został wybrany algorytm Keccak. Ponieważ jak dotąd nie zostały zaprezentowane żadne liczące się w praktyce metody ataku na SHA-2 jest on wciąż uważany za bezpieczny, a SHA-3 jest przygotowywany jako alternatywa gdyby takie metody zostały opracowane.
\end{solution}

\question Na czym polega paradoks urodzinowy i jak wykorzystać go do ataku na MAC?
\begin{solution}
Paradoks urodzinowy to zaskakująca obserwacja z rachunku prawdopodobieństwa dla grupy liczącej  $k$ osób. Polega ona na zestawieniu szansy na to ktoś ma urodziny konkretnego dnia, z tym, że dowolne dwie osoby w grupie mają urodziny tego samego dnia. O ile pierwsza wartość wynosi $P_1 = k/365$, o tyle druga $P_2 = 1 - \frac{364}{365}\frac{363}{365} ... \frac{365-k+1}{365}$. 
Na przykład, jeśli $k=20$, to $P_1 = 0.06$, a $P_2 = 0.44$. 
\end{solution}

\question Oszacuj czas ataku brute-force na hasło składające się z 6 małych liter, przy założeniu, że algorytm atakujący wykonuje $10^6$ prób na sekundę.
\begin{solution}
Liczba wszystkich możliwych haseł wynosi w tym przypadku $26^6$. Statystycznie atak brute-force musi przeszukać połowę tej liczby, co zajmie mu $(26^6 / 2 ) / 10^6 \approx 154$ sekund.
\end{solution}

\question Zaproponuj wymagania na hasło, tak aby niosło około 60 bitów entropii.
\begin{solution}
Przy założeniu, że hasło jest w pełni losowe jego entropia wynosi $n \log_2(N)$, gdzie $n$ to liczba znaków, a $N$ jest liczbą znaków w stosowanym alfabecie. Jeżeli przyjmiemy hasło składające się z samych cyfr, czyli $N=10$, aby otrzymać 60 bitów potrzebnych będzie $60/\log_2(10) \approx 18$ znaków. Natomiast w przypadku hasła składającego się z małych i dużych liter, będzie to $60/\log_2(52) \approx 10 $ znaków
\end{solution}


\end{questions}


\subsection{Algorytmy asymetryczne}

\begin{questions}
\question Przedstaw metodę generowania kluczy w algorytmie RSA.
\begin{solution}
Etap generowanie kluczy jest specyfiką wszystkich algorytmów asymetrycznych. Występuje on jednorazowo przed rozpoczęciem jakiegokolwiek szyfrowania. Raz wygenerowana para kluczy (prywatny i publiczny) może być wykorzystywana wielokrotnie. 

Dla algorytmu RSA wygląda to następująco:
\begin{enumerate}
\item Losujemy dwie duże liczby pierwsze $p$ i $q$.
\item Wybieramy losowo liczbę $e$ względnie pierwszą z $(p-1)(q-1)$, czyli $NWD(e, (p-1)(q-1)) = 1$.
\item Obliczamy liczbę $d$ będącą odwrotnością $e$ modulo $(p-1)(q-1)$, czyli $ ed = 1 mod (p-1)(q-1)$.
\item Obliczamy liczbę n, $n = pq$, a następnie niszczymy $p$ i $q$. 
\end{enumerate}
Kluczem prywatnym jest para liczb $(e,n)$, a kluczem publicznym $(d,n)$.
\end{solution}

\question Omów szyfrowanie i deszyfrowanie w algorytmie RSA.
\begin{solution}
Zakładając, że $(e,n)$ jest kluczem prywatnym, a $(d,n)$ kluczem publicznym. Zaszyfrowanie wiadomości $M$ sprowadza się do przekształcenia jej w liczbę (nazwijmy tą liczbę $m$) i wykonaniu operacji podnoszenia do potęgi $d$ modulo $n$:
\begin{equation}
 c = m^d \pmod{n}
\end{equation}
Odszyfrowanie to bardzo podobna operacja matematyczna wykonaną na kryptogramie $c$, wykorzystująca jednak klucz prywatny:
\begin{equation}
 m = c^e \pmod{n}
\end{equation}
\end{solution}

\question Omów szyfrowanie i deszyfrowanie w algorytmie ElGamal.
\begin{solution}
Załóżmy, że $(p,\alpha,\beta)$ jest kluczem publicznym, a $(t)$ kluczem prywatnym. Zaszyfrowanie wiadomości $M$ sprowadza się do przekształcenia jej w liczbę (nazwijmy tą liczbę $m$) i wykonaniu dwóch obliczeń:
\begin{equation}
 (c_1, c_2) = (\alpha^k, m\beta^k) \pmod{p}
\end{equation}
gdzie $k$ jest dużą liczbą losową. Kryptogram $c$ składa się z dwóch liczb na każdą liczbę tekstu jawnego. W przypadku szyfrowania dłuższego ciągu liczb, można wykorzystać tą samą liczbę losową $k$, tym samym $\alpha^k$ będzie jedno, zmniejszając w ten sposób długość kryptogramu.
  
Odszyfrowanie to jedna operacja matematyczna:
\begin{equation}
 m = c_2({c_1}^t)^{-1} \pmod{p}
\end{equation}
\end{solution}

\question Udowodnij zasadę odszyfrowywania w algorytmie ElGamal.
\begin{solution}
Wiemy, że kryptogram w algorytmie ElGamal składa się z dwóch liczb:
\begin{equation}
 (c_1, c_2) = (\alpha^k, m\beta^k) \pmod{p}
\end{equation}
gdzie $k$ jest dużą liczbą losową, $(p,\alpha,\beta)$ jest kluczem publicznym, a $(t)$ kluczem prywatnym. 
Odszyfrowanie to jedna operacja matematyczna:
\begin{equation}
 m = c_2({c_1}^t)^{-1} \pmod{p}
\end{equation}
Pamiętając podstawową relację $\beta=\alpha^t$, możemy udowodnić działanie algorytmu:
\begin{equation}
 c_2({c_1}^t)^{-1} = m\beta^k (\alpha^{kt})^{-1} =  m\alpha^{kt} (\alpha^{kt})^{-1}  = m \pmod{p}
\end{equation}
\end{solution}

\question Przedstaw podstawowy schemat wykorzystania kryptografii asymetrycznej do szyfrowania.
\begin{solution}
W kryptografii asymetrycznej używane są dwa rodzaje kluczy - klucz publiczny i klucz prywatny. Klucz publiczny użytkownika jest powszechnie znany, natomiast do klucza prywatnego dostęp ma tylko jego właściciel. Wynika z tego, że kluczem publicznym zaszyfrowujemy informacje, a klucz prywatny służy do jej odczytu. Prosty schemat:
\begin{enumerate}
\item Alicja chce wysłać zaszyfrowaną wiadomość do Boba. Klucz publiczny Boba jest ogólnodostępny (np. umieszczony w jego podpisie na forum dyskusyjnym). Alicja szyfruje swoją wiadomość kluczem publicznym Boba i wysyła do niego.
\item Bob otrzymuje zaszyfrowaną wiadomość. Używa swojego klucza prywatnego do jej odszyfrowania.
\end{enumerate}
\end{solution}

\question Przedstaw podstawowy schemat wykorzystania kryptografii asymetrycznej do podpisu.
\begin{solution}
\begin{enumerate}
\item Alicja chce zagwarantować autentyczność wiadomości. Zaczyna od obliczenia jej hasha. Następnie szyfruje ten hash swoim kluczem prywatnym i dołącza go jako podpis do oryginalnej wiadomości.
\item Dowolna osoba posiadająca klucz publiczny Alicji może sprawdzić autentyczność podpisu, poprzez odszyfrowanie hasha za pomocą klucza publicznego Alicji i porównanie go z samodzielnie wyliczonym.
\end{enumerate}
\end{solution}

\question Wymień wady i zalety kryptografii asymetrycznej.
\begin{solution}
Kryptografia asymetryczna rozwiązuje problem ustalania klucza, który jest poważnym utrudnieniem przy masowym stosowaniu kryptografii symetrycznej. Ponadto stwarza nowe możliwości (np. uwierzytelnianie) definiowane przez wykorzystanie schematu podpisu (szyfrowanie kluczem prywatnym). Do wad kryptografii asymetrycznej należy zaliczyć większą złożoność obliczeniową stosowanych algorytmów oraz większość długość wymaganych kluczy.
\end{solution}


\question Wyjaśnij znacznie zapisu $x = y^{-1} \pmod{n}$.
\begin{solution}
Oznacza to, że liczba $x$ jest odwrotnością liczby $y$ w arytmetyce modularnej. Jest to równoważne z tym, że iloczyn tych liczb jest równy $1$, co można zapisać jako $x y = 1 \pmod{n}$.
\end{solution}

\question Scharakteryzuj szyfrowanie oparte na krzywych eliptycznych.
\begin{solution}
Algorytmy oparte na krzywych eliptycznych (ECC) wymagają kilkukrotnie krótszych kluczy niż inne algorytmy asymetryczne, np. RSA, przy tym samym poziomie odporności. Na przykład, klucz o długości 1024 bitów w RSA odpowiada 163 bitowemu kluczowy ECC.
Dodatkowo wykonywane obliczenia są stosunkowo proste, a więc nie wymagają dużej mocy obliczeniowej od urządzeń szyfrujących.
\end{solution}

\question Wyjaśnij działanie probabilistycznych testów pierwszości.
\begin{solution}
Test pierwszości to algorytm określający, czy dana liczba jest pierwsza, czy złożona. Probabilistyczny test pierwszości przebiega w następujący sposób:
\begin{enumerate}
\item Wybieramy losowo liczbę $a$.
\item Sprawdzamy pewne równanie zawierające $a$ oraz zadaną liczbę $n$. Jeśli okaże się fałszywe, zwracamy wynik \textit{n jest złożona}.
\item Powtarzamy procedurę aż uzyskamy wystarczającą pewność.
\end{enumerate}
Jeśli w wystarczająco wielu próbach nie uda się stwierdzić złożoności $n$, test zwraca odpowiedź \textit{n jest prawdopodobnie pierwsza}.
\end{solution}

\question Opisz algorytm szybkiego potęgowania.
\begin{solution}
\fixit
Algorytm szybkiego potęgowania pozwala obliczać potęgi całkowite dużych liczb. Opiera się na spostrzeżeniu, że do obliczenia wartości wyrażenia $x^n$ wystarczy wykonanie maksymalnie $\frac{n}{2} + 1$ mnożeń, zgodnie z właściwością potęgowania: $x^n = x * x^{n-1}$.

\medskip
Treść algorytmu:\\
Wejście: $x,n \in N$,
Wyjście: $w \in N$
\begin{verbatim}
potęga(x, n):
  jeżeli n = 0 
    zwróć 1;
  jeżeli n nieparzysta
    zwróć x * potęga (x, n-1);
  jeżeli n parzysta
    a = potęga (x, n/2);
    w = a * a;
    zwróć w;
\end{verbatim}

Algorytm interacyjny jest chyba czytelniejszy.

\end{solution}

\question Oblicz liczbę odwrotną do $34 \pmod{77}$.
\begin{solution}
\fixit
Za pomocą rozszerzonego algorytmu Euklidesa:\\

$ax + by = NWD(a,b)$\\
$a = 34, b = 77$\\

$NWD(34,77) = 1$ , więc liczby są względnie pierwsze - liczba $x$ jest odwrotnością modulo $77$ liczby $34$ .\\ 

$ 34 * u + 77 * v = w$\\
$ 34 * x + 77 * y = z$\\

Tworzę parę równań :\\
$ 34 * 1 + 77 * 0 = 34$\\
$ 34 * 0 + 77 * 1 = 77$\\

Ponieważ $34 < 77$, równania zamieniam miejscami:\\
$ 34 * 0 + 77 * 1 = 77$\\
$ 34 * 1 + 77 * 0 = 34$\\
Obliczam iloraz $q = 77 / 34 = 2$\\
Od równania (1) odejmuję (2) pomnożone przez q:\\
$ 34 * (0 - 2 * 1)  + 77 * (1 - 2 * 0) = 77 - 2 * 34$\\
$ 34 * (-2) + 77 * 1 = 9$\\
$ 34 * 1 + 77 * 0 = 34$\\

Ponieważ $9 < 34$, równania zamieniam miejscami:\\
$ 34 * 1 + 77 * 0 = 34$\\
$ 34 * (-2) + 77 * 1 = 9$\\

Obliczam iloraz $q = 34 / 9 = 3$\\
$ 34 * (1 - 3 * (-2)) + 77 * (0 - 3 * 1) = 34  - 3 * 9$\\
$ 34 * 7 + 77 * (-3) = 7$\\
$ 34 * (-2) + 77 * 1 = 9$\\

Ponieważ $7 < 9$, równania zamieniam miejscami:\\
$ 34 * (-2) + 77 * 1 = 9$\\
$ 34 * 7 + 77 * (-3) = 7$\\

Obliczam iloraz $q = 9 / 7 = 1$\\
$ 34 * ((-2) - 1 * 7) + 77 * (1 - 1 * (-3)) = 9 - 1 * 7$\\
$ 34 * (-9) + 77 * 4 = 2$\\
$ 34 * 7 + 77 * (-3) = 7$\\

Ponieważ $2 < 7$, równania zamieniam miejscami:\\
$ 34 * 7 + 77 * (-3) = 7$\\
$ 34 * (-9) + 77 * 4 = 2$\\

Obliczam iloraz $q = 7 / 2 = 3$\\
$ 34 * (7 - 3 * (-9)) + 77 * ((-3) - 3 * 4) = 7 - 3 * 2$\\
$ 34 * 34 + 77 * (-15) = 1$\\
$ 34 * (-9) + 77 * 4 = 2$\\
Ponieważ $1 < 2$, równania zamieniam miejscami:\\
$ 34 * (-9) + 77 * 4 = 2$\\
$ 34 * 34 + 77 * (-15) = 1$\\

Obliczam iloraz $q = 2 / 1 = 2$\\
$ 34 * ((-9) - 2 * 34)  + 77 * (4 - 2 * (-15)) = 2 - 2 * 1$\\
$ 34 * (-77) + 77 * 34 = 0$\\
$(2) 34 * 34 + 77 * (-15) = 1$\\

Otrzymuję $w = 0$, kończę modyfikowanie równań. Wyniki są następujące:\\
$u = -77,  v = 34,  w = 0$\\
$x = 34, y = 77,  z = 1$\\

Ponieważ $z = NWD(a,b) = NWD(34,77) = 1$, to odwrotność istnieje i jest równa $34$.\\

Sprawdzam, czy otrzymany wynik spełnia definicję odwrotności modulo:\\
$a * x mod b = 34 * 34 mod 77 = 1156 mod 77 = 1$\\

Wynik się zgadza, więc szukana wartość:\\
$x = 34$
\end{solution}

\question Korzystając algorytmu Euklidesa sprawdź, czy liczby 57 i 123 są względnie pierwsze.
\begin{solution}
Tworzymy ciąg reszt z dzielenia:
$r_0 = 123$, $r_1 = 57$, $r_3 = 123 - 2 \times 57 = 9$, $r_4 = 57 - 6 \times 9 = 3$, 
$r_5 = 9 - 3 \times 3 = 0$. Okazało się, że największym wspólnym dzielnikiem liczb 57 i 123 jest liczba 3, co oznacza, że liczby te nie są względnie pierwsze.
\end{solution}

\question Na czym polegają operacje w kryptografii krzywych eliptycznych?
\begin{solution}
Główne operacje dotyczą punktów (x,y) spełniających równanie eliptyczne w arytmetyce modularnej. 
\begin{equation}
y^2 = x^3 + ax +b \pmod{p}
\end{equation}
Operacje dodawania, mnożenia są zdefiniowane matematycznie, jednak ich obliczenie może nie być proste. Na przykład prosta na pierwszy rzut oka operacja mnożenia punktu $A$ przez skalar $k$:
\begin{equation}
R = k A \pmod{p}
\end{equation}
jest łatwa do wykonania w jedną stronę, jednak bardzo trudna do odwrócenia. Na tym właśnie bazuje kryptografia krzywych eliptycznych.

\end{solution}

\question Wyjaśnij pojęcie świadka złożoności.
\begin{solution}
Świadek złożoności $p$ jest losowo wybraną liczbą podczas
przeprowadzania probabilistycznych testów pierwszości. Jeżeli w
procesie iteracyjnym pewne równanie uwzględniające liczbę badaną oraz
$p$ jest fałszywe, to liczba badana jest złożona, a $p$ jest świadkiem
złożoności.
\end{solution}

\question Omów algorytm plecakowy.
\begin{solution}
\fixit
Algorytm plecakowy jest asymetrycznym szyfrem opierającym się na maksymalizacyjnym problemie wyboru przedmiotów tak, by ich sumaryczna wartość była jak największa i jednocześnie mieściły się w plecaku. Generowane klucze tworzone są za pomocą dwóch problemów plecakowych - łatwego (klucz publiczny do szyfrowania) i trudnego (klucz prywatny do deszyfrowania). Reprezentacje wag dla danego problemu reprezentowane są liczbą binarną, np. w sytuacji dostępnych wag : $1, 6, 8, 15, 24$ przy ograniczeniu $40$ rozwiązaniem problemu plecakowego będzie : $1+15+24 = 40$, co zostanie przedstawione liczbą : $10011$.
\end{solution}

\end{questions}

\subsection{Steganografia}

\begin{questions}

\question Na czym polega steganografia? Podaj przykłady historyczne.
\begin{solution}
Steganografia polega na ukrywaniu faktu istnienia informacji, a także na ukrywaniu kanału komunikacyjnego. O starożytności mamy wiele metod tego typu, np: atrament sympatyczny, mikrokropki, tatuaż pod włosami.
\end{solution}

\question Jakiego rodzaju dane cyfrowe mogą być nośnikiem kanału steganograficznego?
\begin{solution}
Nośnikiem steganograficznym mogą być każde dane, które mają w sobie pewną nadmiarowość. Idealnie w tej funkcji sprawdzają się materiały multimedialne, zdjęcia, filmy, muzyka. Jednak równie dobrze informacja może zostać ukryta w innych plikach danych, które mogą zostać zmodyfikowane bez zmiany niesionej informacji np. HTML, DOC, PDF. W protokołach sieciowych też jest wpisana pewna dowolność, a więc otwiera się pole dla steganografii. 
\end{solution}

\question Omów dwa główne zastosowania steganografii?
\begin{solution}
Technika ukrywania informacji może być stosowana do utajnionej komunikacji oraz do znakowania wodnego danych. Od strony algorytmicznej są to właściwie identyczne problemy. Różnica tkwi tylko w tym co jest głównym przedmiotem metody. W pierwszym przypadku jest to ukryta informacja, a w drugim nośnik steganograficzny. 
\end{solution}

\question Wyjaśnij na czym polega pasywna steganoanaliza?
\begin{solution}
Pasywna steganoanaliza polega na wykrywaniu kanału steganograficznego. Samo wykrycie informacji, to najczęściej tylko pierwszy krok, albowiem jest ona zaszyfrowana. W celu pełnego poznania komunikatu konieczne jest przeprowadzenie również ataku kryptoanalitycznego.
\end{solution}

\question Wyjaśnij na czym polega aktywna steganoanaliza?
\begin{solution}
Aktywna steganoanaliza polega na zakłóceniu lub całkowitym zniszczeniu ukrytej wiadomości. Metody te są wykorzystywane do usuwania cyfrowych znaków wodnych z treści multimedialnych, lub do niszczenia kanału steganograficznego. Co istotne algorytmy niszczące działają najczęściej na ślepo i nie wymagają żadnej wiedzy o zastosowanej metodzie steganograficznej.  
\end{solution}

\question Przedstaw popularny schemat znakowania wodnego obrazów cyfrowych?
\begin{solution}
Celem znakowania wodnego jest trwałe oznaczenie materiału multimedialnego danymi autora, dystrybutora, lub właściciela kopii. Proces rozpoczyna się od tego, że dane nośnika poddawane są transformacji (np. fft, kosinusowej, falkowej). Dane identyfikacyjne poddawane są kodowaniu rozszerzającemu, aby zwiększyć ich odporność na uszkodzenia. Następnie oba te sygnały są dodawane, a wynik przechodzi przez transformację odwrotną, dzięki czemu nośnik wraca do normalnej formy.
\end{solution}

\question Przedstaw ogólny schemat tworzenia kanału steganograficznego?
\begin{solution}
Kanał steganograficzny ma za zadanie w ukryty sposób przekazać tajną wiadomośći. Proces rozpoczyna się od zaszyfrowania wiadomości, aby zapewnić jej poufność i zatrzeć cechy statystyczne. Jednocześnie dane nośnika poddawane są transformacji (np. fft, kosinusowej, falkowej). Następnie oba te sygnały są dodawane, a wynik przechodzi przez transformację odwrotną, dzięki czemu nośnik wraca do normalnej formy.
\end{solution}


\end{questions}



\section{Protokoły}

\subsection{Dystrybucja kluczy publicznych}

\begin{questions}

\question Co to jest PKI? Jakie ma zalety, a jakie wady?
\begin{solution}
PKI - Public Key Infrastructure, po polsku Infrastruktura Klucza Publicznego. Jest to zorganizowana metoda dystrybucji kluczy publicznych opierająca się na certyfikatach i drzewiastej strukturze urzędów certyfikujących (CA). Rolą CA jest uprzednie stwierdzenie tożsamości, a następnie poświadczenie jej przez złożenie podpisu cyfrowego na kluczu publicznym zainteresowanego. Centralizacja w formie urzędów certyfikujących może być przez jednych traktowana jako zaleta, bo odpowiedzialność za system jest skupiona na określonej grupie organizacji. Jednak CA mogą stać się celem ataków, przez cały system stanie się niewiarygodny.
\end{solution}

\question Wyjaśnij dlaczego certyfikaty urzędów certyfikujących są wbudowane w system operacyjny?
\begin{solution}
Wiarygodność certyfikatu urzędu certyfikującego (CA, ang. Certification Authority) stoi u podstaw całej infrastruktury klucza publicznego (PKI). Dlatego też bardzo ważne jest, aby te certyfikaty były dystrybuowane możliwie pewnym kanałem i rzadko ulegały zmianom. Najczęściej certyfikaty CA instalowane są razem z systemem operacyjnym, lub samym programem, który będzie wykorzystywał połączenia szyfrowane (np. przeglądarka internetowa).
\end{solution}

\question Na czym polega Web-of-trust?
\begin{solution}
Web-of-trust to rozproszona metoda dystrybucji kluczy publicznych, alternatywna do hierarchicznej infrastruktury klucza publicznego. Użytkownicy systemu tworzą sieć wzajemnie poświadczając sobie klucze publiczne. Jeden klucz może być podpisywany przez wielu użytkowników, którzy mają możliwość ustawiania różnych poziomów zaufania. Popularna implementacja Web-of-trust wykorzystywana jest w systemie PGP.
\end{solution}

\question W jaki sposób dystrybuowane są klucze publiczne w protokole SSH?
\begin{solution}
Klucze publiczne w protokole SSH są przechowywane w pliku $\sim$/.ssh/authorized\textunderscore keys po stronie serwera.
Umieszczenie klucza publicznego w pliku authorized\textunderscore keys (przy pomocy programu ssh-copy-id lub ręcznie) pozwala na logowanie się przez SSH bez konieczności podawania hasła. Eliminujemy w ten sposób ataki na słabe hasła zapamiętywane przez człowieka. Jednocześnie powstaje zagrożenie, gdyby klucz prywatny powiązany z kluczem publicznym trafił w niepowołane ręce.
\end{solution}

\question Co to jest certyfikat X.509 i jakie są jego najważniejsze elementy?
\begin{solution}
Rolą systemu certyfikatów X.509 jest rozprowadzenie kluczy publicznych ich właścicieli. Podstawowymi elementami certyfikatu są: klucz publiczny w wybranym protokole, dane właściciela, daty ważności oraz podpis wystawcy, który jest gwarantem wiarygodności certyfikatu.
\end{solution}

\end{questions}


\subsection{Uwierzytelnianie}

\begin{questions}


\question Czym różni się uwierzytelnianie od autoryzacji?
\begin{solution}
Uwierzytelnianie jest procesem potwierdzenia tożsamości, natomiast autoryzacja dotyczy przyznania uprawnień. Bardzo często te dwa kroki następują po sobie, jednak należy je zdecydowanie rozróżniać, bo wiążą się z nimi zupełnie inne problemy.
\end{solution}

\question Opisz dowolny iteracyjny protokół uwierzytelniania.
\begin{solution}
Iteracyjne protokoły uwierzytelniania są szczególnym przypadkiem protokołów Wyzwanie-Odpowiedź, w których jednorazowe pytanie nie daje odpowiedzi na pytanie o tożsamość użytkownika. 

Najprostszym do opisania protokołem tego typu jest dowód z wiedzą zerową na przykładzie tajemnych drzwi w jaskini. W protokole tym jedna osoba dowodzi, że zaklęcie otwierające drzwi, a weryfikujący nie wie nawet, czy i kiedy zaklęcie zostało użyte. Protokół musi być wykonany wiele razy, żeby w sposób wiarygodny przekonać weryfikującego.
\end{solution}

\question Omów wady i zalety uwierzytelniania przy pomocy hasła.
\begin{solution}
Uwierzytelniania przy pomocy tajnego hasła jest najpopularniejszą metodą potwierdzania tożsamości. Stosowane jest od czasów starożytnych i jest naturalnie zrozumiałe przez ludzi. 
Do zalet tej metody należy zaliczyć: łatwość w implementacji, powszechne zrozumienie zasady działania.
Wadami są: możliwość podsłuchania hasła, konieczność przechowywania hasła na serwerze, dobre hasła są trudne do zapamiętania przez użytkowników.
\end{solution}

\question Przedstaw trzy główne grupy metod uwierzytelniania.
\begin{solution}
Metody uwierzytelniania ludzi przez systemy komputerowe możemy podzielić na trzy grupy w zależności od tego do czego się odwołują:
\begin{description}
\item[Co wie?] - odwołujące się do zapamiętanych haseł,
\item[Co ma?] - odwołujące się do posiadanych przedmiotów,
\item[Kim jest?] - odwołujące się do cech biometrycznych.
\end{description}
\end{solution}

\question Na czym polega uwierzytelnianie dwuskładnikowe? Podaj przykłady.
\begin{solution}
Uwierzytelnianie dwuskładnikowe polega na potwierdzeniu tożsamości użytkownika poprzez wykorzystanie dwóch różnych metod uwierzytelniania. Metody uwierzytelniania mogą odwoływać się do wiedzy użytkownika, czegoś co posiada lub tego jaki jest. Dobrym przykładem jest operacja wypłacenia pieniędzy z bankomatu. Użytkownik potwierdza tożsamość posiadając kartę (coś co ma) oraz znając numer PIN (coś co wie). Drugim przykładem może być uwierzytelnianie użytkownika przed wpuszczeniem go do wysoce chronionego miejsca. Może się to odbywać poprzez skanowanie siatkówki oka (jaki jest), odcisk palca (jaki jest) oraz podanie kodu. Mimo że takie uwierzytelnianie będzie posiadało trzy etapy, również jest dwuskładnikowe, ponieważ odwołuje się do dwóch różnych metod.
\end{solution}

\question Przedstaw schemat uwierzytelniania wyzwanie-odpowiedź w oparciu o kryptografię symetryczną.
\begin{solution}
Przykładowy schemat w oparciu o kryptografię symetryczną:\\
Wcześniej klient i serwer ustalają tajny klucz do szyfrowania używając innego kanału.
\begin{enumerate}
\item Klient podaje swoje dane identyfikacyjne.
\item Serwer losuje $r$ i wysyła klientowi.
\item Klient szyfruje $r$ i odsyła do banku.
\item Serwer również szyfruje $r$ i porównuje wyniki, jeśli są zgodne, klient zostaje uwierzytelniony.
\end{enumerate}
\end{solution}

\question Przedstaw schemat uwierzytelniania wyzwanie-odpowiedź w oparciu o kryptografię asymetryczną.

\begin{solution}
Przykładowy schemat w oparciu o uwierzytelnianie z wykorzystaniem kluczy RSA klienta w protokole SSH2:
\begin{enumerate}
\item Klient przesyła do serwera swój klucz publiczny.
\item Serwer sprawdza w wewnętrznej bazie kluczy czy przesłany klucz faktycznie odpowiada danemu klientowi.
\item Jeśli klucze są zgodne serwer wysyła do klienta losowe dane (np. liczbę) zaszyfrowane jego kluczem publicznym.
\item Klient odszyfrowuje dane swoim kluczem prywatnym i odsyła do serwera.
\item Serwer porównuje otrzymane dane z wysłanymi przez siebie, jeśli są zgodne klient zostaje uwierzytelniony.
\end{enumerate}
\end{solution}

\question Omów podstawowy schemat iteracyjnego dowodu z wiedzą zerową.

\end{questions}


\subsection{Podpis cyfrowy}

\begin{questions}

\question Omów podstawowy schemat podpisu cyfrowego.
\begin{solution}
Schemat składa się z dwóch etapów generowania i weryfikacji podpisu cyfrowego.

Generowanie podpisu:
\begin{enumerate}
\item Podpisujący wylicza hash wiadomości.
\item Hash jest szyfrowany kluczem prywatnym podpisującego.
\item Zaszyfrowana wartość hash to właśnie podpis elektroniczny.
\end{enumerate}

Weryfikacja podpisu:
\begin{enumerate}
\item Odbiorca wyznacza hash z otrzymanej wiadomości.
\item Deszyfruje podpis używając klucza publicznego nadawcy.
\item Jeśli obie wartości hash są równe to podpis jest prawidłowy, a wiadomość wiarygodna.
\end{enumerate}
\end{solution}


\question Wyjaśnij jakie znaczenie ma zastosowanie funkcji haszującej w podpisie cyfrowym.
\begin{solution}
W najprostszym schemacie podpisu cyfrowego procedura polega na zaszyfrowaniu podpisywanego dokumentu naszym kluczem prywatnym. Jednak problemem w takim rozwiązaniu jest fakt, iż sam podpis jest wówczas tej samej długości co dokument, a więc trzeba wysłać dwa razy więcej informacji. Zastosowanie funkcji haszującej rozwiązuje ten problem, gdyż szyfrujemy jedynie hash z oryginalnego dokumentu, a nie całą treść, dzięki czemu podpis jest krótszy a nadal spełnia swoją rolę.
\end{solution}


\question Jakie zagrożenia niesie za sobą podpisywanie niezrozumiałych danych?
\begin{solution}
Możliwe jest, że dane zostały spreparowane w ten sposób, aby poznać nasz klucz prywatny bądź dokonać podpisu podstawionej wiadomości. W przypadku algorytmu RSA jest to stosunkowo proste. Wystarczy, że atakujący przykryje wiadomość $m$ poprzez pomnożenie jej przez losowe $k$ do potęgi $e$ (nasz klucz publiczny). 
\begin{equation}
t = m k^e \pmod{n}
\end{equation}
Podpisując niezrozumiałe, losowo-wyglądające $t$ przy pomocy klucza prywatnego $d$ wykonujemy operację
\begin{equation}
s = t^d \pmod{n}
\end{equation}
Ponieważ z $k^{ed} = k$, atakujący może wykonać następującą operację:
\begin{equation}
sk^{-1} = m^d \pmod{n}
\end{equation}
otrzymując w ten sposób poprawny podpis wiadomości $m$ naszym kluczem prywatnym.
\end{solution}

\end{questions}


\subsection{Ustalanie kluczy}
\begin{questions}

\question Przedstaw prosty protokół uzgadniania kluczy, który równo rozkłada odpowiedzialność pomiędzy dwie strony komunikacji.
\begin{solution}
Celem protokołu jest ustalenie klucza, który będzie mógł być zastosowany do szyfrowania symetrycznego. 
\begin{enumerate}
\item Ala wybiera losową liczbę $r_A$ i przesyła ją do Boba,
\item Bob wybiera losową liczbę $r_B$ i przesyła ją do Ali,
\item Ala i Bob niezależnie obliczają $hash(r_A, r_B)$ i traktują go jako klucz.
\end{enumerate}
Protokół ten jest wrażliwy na podsłuch, jednak obie strony w jednakowym stopniu odpowiadają za bezpieczeństwo klucza.
\end{solution}

\question Omów protokół Diffie-Helmana.
\begin{solution}
Protokół Diffie-Helmana służy do ustalenia klucza szyfrowania przez niezabezpieczony kanał przesyłu danych. Jest jednym z pierwszych praktycznych rozwiązań tego typu problemów w historii. Jego siłą jest brak skutecznego algorytmu do obliczania logarytmów dyskretnych w arytmetyce modularnej. Protokół nie jest wrażliwy na podsłuch o ile elementy $p$ i $g$ są dobrane poprawnie. W celu zwiększenia bezpieczeństwa liczba $p$ oraz liczby $a$ i $b$ powinny być długie. Oto schemat protokołu:
\begin{enumerate}
\item Alicja i Bob ustalają publiczną liczbę pierwszą $p$ oraz publiczną podstawę obliczeń $g$.
\item Alicja wybiera sobie tajną liczbę $a$ i oblicza wartość $A=g^{a} \pmod{p}$, następnie wysyła obliczoną wartość $A$ do Boba.
\item Bob wybiera sobie tajną liczbę $b$ i oblicza wartość $B=g^{b} \pmod{p}$, następnie wysyła obliczoną wartość $B$ do Alicji.
\item Alicja oblicza $s=B^{a} \pmod{p}$
\item Bob oblicza $s=A^{b} \pmod{p}$
\end{enumerate}
Alicja i Bob współdzielą tajną wartość $s$, za pomocą której mogą szyfrować dalszą komunikację. Dzieje się tak ponieważ $g^{ab}=g^{ba}=s \pmod{p}$, czyli tylko osoba znająca obie tajne wartości $a$ i $b$ mogłaby obliczyć wartość $s$. Trudność problemu logarytmu dyskretnego powoduje, że publicznie znane liczby $A$ i $B$ nie umożlwiają odtworzenia $a$ i $b$.
\end{solution}

\question Omów protokół Diffie-Helmana oparty na krzywych eliptycznych.
\begin{solution}
\end{solution}

\question Omów protokół Interlock.
\begin{solution}
Ciekawy protokół mający za zadanie zapobiegać atakom man-in-the-middle. Podstawową zasadą jest to, że nie deszyfruje się klucza mając tylko połowę kryptogramu(0.5 krypto$=>$ 0.5 tekstu jawnego). Istnieją jednak skuteczne ataki na ten protokół.

\begin{enumerate}
\item A wysyła do B swój klucz publiczny i na odwrót
\item B szyfruje wiadomość tekstową za pomocą klucza publicznego A i wysyła pierwszą połowę kryptogramu
\item A otrzymuje 0.5 kryptogramu, tworzy swoją wiadomość tekstową, szyfruje ją i tez wysyła do B 0.5 kryptogramu
\item B otrzymuje 0.5 kryptogramu od A i przesyła swoja drugą połowę
\item A otrzymuje druga połowę i deszyfruje ją swoim kluczem prywatnym. A sprawdza czy wiadomość ma sens. Jeśli ma to kanał jest ok, więc wysyłamy 2 połowę do B
\item B deszyfruje wiadomość. Jeśli ma sens to wszystko jest w porządku.
\end{enumerate}

\end{solution}


\end{questions}


\subsection{Inne}

\begin{questions}

\question Na czym polegają protokoły dzielenia tajemnic? 
\begin{solution}
Dzielenie tajemnic jest sposobem rozdzielenie sekretu pomiędzy kilku użytkowników w taki sposób, że żaden z nich samodzielnie nie może go odzyskać. Przydatność takiej metody prosto pokazać na przykładzie: Pewna firma jest w posiadaniu ważnych informacji, np. decydującej o jej przewadze technologicznej nad konkurencją. Informacje te muszę być chronione i dlatego znajdują się w sejfie. Aby dodatkowo zwiększyć bezpieczeństwo, sejf może zostać otwarty tylko wtedy, gdy wszystkie osoby z zarządu firmy użyją swych kluczy (protokół bez progu). Wygodniejsza wersja powyższego scenariusza zakłada, że do otworzenia sejfu wystarcza, powiedzmy, 2/3 kluczy (tak aby sejf nie został zablokowany, np. absencją chorobową pojedynczych członków zarządu) (protokół z progiem). Oczywiście, najlepiej, gdy sejf ma postać protokołu kryptograficznego – eliminuje to konieczność drogich szaf pancernych.
\end{solution}

\question{Wyjaśnij dlaczego proste podzielenie tajemnicy na fragmenty nie jest dobrym rozwiązaniem?}
\begin{solution}
Proste dzielenie tajemnic na fragmenty nie jest dobrym rozwiązaniem gdyż wówczas każdy z udziałowców mimo iż otrzymuje fragment całości, to jest to fragment kompletny i sensowny w swoim zakresie, zatem zbierając wiele fragmentów od wielu udziałowców można w znacznym stopniu odtworzyć pierwotną tajemnicę. Protokoły dzielenia tajemnic rozwiązują ten problem gdyż wtedy potrzebni są wszyscy udziałowcy lub ich z góry założona ilość (dla protokołow z progiem odzyskania tajemnicy). W przypadku zgromadzenia mniejszej ilości udziałów nie daje to żadnej przewagi gdyż nie ma możlwości odzyskania części tajemnicy.
\end{solution}

\question{Omów wybrany przykład protokołu dzielenia tajemnicy.}
\begin{solution}
Przedstawmy najprostszy protokół bez progu opierający działanie na funkcji XOR ($\oplus$):
\begin{itemize}
\item tworzymy $n-1$ losowych ciągów $X_1, X_2, X_3, ..., X_{n-1}$
\item obliczamy $X_n = S \oplus X_1 \oplus X_2 \oplus X_3 \oplus ... \oplus X_{n-1}$ 
\item rozdajemy tajemnicę użytkownikom w ten sposób, że użytkownik 1 otrzymuje $X_1$, użytkownik 2 $X_2$ itd.
\item odtworzenie tajemnicy polega na obliczeniu $S = X_0 \oplus X_1 \oplus X_2 \oplus X_3 \oplus ... \oplus X_{n}$
\end{itemize}
\end{solution}

\question{Przedstaw wybrany protokół dzielenia tajemnicy z progiem.}
\begin{solution}
Protokoły dzielenia tajemnicy z progiem pozwalają dowolnie ustalić liczbę osób, które będą konieczne do odtworzenia tajemnicy. Liczba ta jest niezależna od całkowitej liczby powierników tajemnicy. Przykładem takiego rozwiązania jest wielomianowy protokół Shamira. Polega on na tym, że dla ustalonego progu $k$ zostają wylosowane współczynniki wielomianu stopnia $k-1$. Kolejnym osobom rozdaje się punkty na krzywej, a do odtworzenia wielomianu wystarczy spotkanie $k$ z nich.
\end{solution}

\question{Omów zasadę podziału tajemnicy w wielomianowym protokole Shamira.}
\begin{solution}
Dwa punkty jednoznacznie wyznaczają  prostą, trzy punkty wyznaczają
parabolę, i ogólnie n punktów wyznacza jednoznacznie wielomian stopnia
n-1. W protokole Shamira mamy nieskończoną ilość fragmentów do
przydzielenia. Osoba dzieląca wybiera wielomian stopnia t-1, którego
wartość np. w zerze jest równa sekretowi. Jako fragmenty sekretu
udostępniane są wartości tego wielomianu w różnych punktach. Zebranie
t punktów pozwala dokonać interpolacji wielomianu i wyznaczyć jego
wartość w zerze.
\end{solution}

\question{Omów zasadę podziału tajemnicy w protokole hiperpłaszczyzn Blackley'a.}
\begin{solution}
W protokole tym definiuje się próg odzyskania tajemnicy - jest on ilością wymiarów przestrzeni w której ukrywamy tajemnicę. Tajemnicą są w tym przypadku współrzędne punktu przecięcia, a udziałami równania prostych (dla progu n=2), płaszczyzn (dla progu n=3) itd. Można wówczas utworzyć dowolną ilość udziałów, z czego do odzyskania tajemnicy konieczne jest n z nich (tyle, ile wynosił założony na początku próg).
\end{solution}

\end{questions}

%%%%%%%%%%%%%%%%%%%%%%
\section{Ochrona danych w praktyce}

\subsection{Programowanie klasyczne}
\begin{questions}

\question Dlaczego czas przetwarzania danych może być źródłem ataku? Jak się przed nim bronić?
\begin{solution}
W wielu algorytmach czas przetwarzania danych zależy od tego jakie są te dane. W związku z tym, należy mieć zawsze na uwadze, że atakujący mierząc dokładnie czas odpowiedzi systemu może wywnioskować z tego jakieś wewnętrzne informacje. Znanych jest wiele ataków tego typu, np. timming-atak na klucz prywatny RSA.
Obroną przed tego typu atakami jest dodanie pewnych losowych modyfikacji opóźniających działanie algorytmu.  
\end{solution}

\question Jakie jest główne źródło ataków na programy komputerowe? Jak bronić się przed tymi atakami?
\begin{solution}
Głównym źródłem ataków są dane wejściowe do programów. Twórcy programu tworzą system zakładając poprawność danych i dobre intencje użytkownika. Dane przesyłane przez atakującego nie spełniają tych warunków, i w ten sposób może on zaburzyć normalne działanie programu. 
Jedynym rozwiązaniem jest konsekwentny brak zaufania do danych i odrzucanie wszystkiego co nie spełnia określonych warunków (tzw. walidacja z negatywnym nastawieniem).
\end{solution}


\question Na czym polega błąd przepełnienia bufora?
\begin{solution}
Błąd przepełnienia bufora polega na tym, że ilość wprowadzanych danych przekracza założenia programisty co do potrzebnego na nie miejsca w pamięci komputera. Ten rodzaj błędu występuje głównie w językach niskiego poziomu (np. C), w których programista samodzielnie zarządza pamięcią. Przepełnienie bufora ma zawsze poważne skutki, albowiem bezpośrednio wpływa na działanie kodu maszynowego. Jest to jedna z popularnych technik ataku na oprogramowanie. 
\end{solution}

\question Omów metody ochrony przed błędami przepełnienia bufora?
\begin{solution}
Główną metodą ochrony przed błędami przepełnienia bufora jest unikanie stosowania funkcji, które nie sprawdzają rozmiaru przyjmowanych danych, a w zamian używanie ich bezpieczniejszych odpowiedników (np. strncpy zamiast strcpy w C). Ogólnie rzecz ujmując, zawsze trzeba brać pod uwagę rozmiar przyjmowanych danych.
\end{solution}

\question Przedstaw najważniejsze zasady walidacji danych.
\begin{solution}
Walidacja, czyli kontrola poprawności danych wejściowych musi dotyczyć wszelkiego rodzaju informacji wprowadzanych do programu. Istotne jest opracowanie reguł, które muszą spełniać dane, żeby mogły być uznane za poprawne. Reguły te powinny być możliwie ścisłe i brać pod uwagę parametry takie jak: format, długość oraz znaczenie danych. Wszystkie dane nie pasujące do reguł powinny zostać odrzucone.  
\end{solution}

\question Na czym polega model security-by-obsurity?
\begin{solution}
,,Security by obscurity'' jest techniką zwiększenia bezpieczeństwa przez pisanie programów w sposób bardzo niejasny i zagmatwany. Skuteczność tej metody jest dosyć wątpliwa.
Już reguła Kerkhoffsa odradzała stosowania takiej techniki: ,,Nie opieramy sie na tajności algorytmu, a na pewności klucza.'' Podkreśla to fakt, iż bezpieczeństwo nie tkwi w tajności budowy algorytmu, ale w jego konstrukcji.
\end{solution}

\question Na czym polega model security-by-design?
\begin{solution}
Polega on na projektowaniu oprogramowania ze szczególnym naciskiem na bezpieczeństwo. Zakłada się, że przyjęta architektura i algorytmy ochrony są wystarczająco dobre do zapewnienia ochrony. Jest to przeciwieństwo modelu security-by-obscurity.

Model secure-by-design oznacza tworzenie oprogramowania w taki sposób, aby już na etapie projektowania uwzględnić kwestie bezpieczeństwa. U podstaw leży założenie, że każdy użytkownik systemu ma złe intencje oraz najwyższe kwalifikacje do przeprowadzania ataków. Na ogół projekty o otwartym kodzie są lepiej poznane i przetestowane ze względu na związaną z nimi społeczność użytkowników (Prawo Linusa).  Z drugiej zaś strony może to ułatwić napastnikom rozpoznanie i znalezienie dziur bezpieczeństwa. 

\end{solution}

\question Na czym polega model security-by-separation?
\begin{solution}
'Security-by-separation' to model, w którym ograniczamy skutki błędów do tylko jednego modułu. Możemy to uzyskać dzięki rozdzieleniu systemu na moduły i zabezpieczaniu każdego  niezależnie od innych, z negatywnym nastawieniem do reszty programu.
\end{solution}

\question Na czym polega model wielopoziomowej ochrony w głąb (ang. in depth defence)?
\begin{solution}
Model ten zakłada istnienie wielu niezależnych warstw zabezpieczeń, dzięki czemu luka w jednej z nich może być kompensowana przez inną. 
\end{solution}
\end{questions}

\subsection{Programowanie internetowe}
\begin{questions}

\question Omów trzy popularne ataki wg. Top10 OWASP
\begin{solution}
Organizacja OWASP zajmuje się analizą stanu i edukacją z zakresie bezpieczeństwa aplikacji internetowych. List Top10 przestawia najpopularniejsze błędy wraz z zaleceniami tego jak ich unikać.
\begin{description}
\item[Injection-Wstrzyknięcie] Ataki polegające na wstrzyknięciu poprzez formularze kodu, który zaburza działanie aplikacji po stronie serwera. Najpopularniejszym przykładem jest SQL Injection, w którym atakowi poddane jest zapytanie SQL. Jednak celem ataku mogą być również inne technologie działające na serwerze, na przykład LDAP, shell, Python (co było demonstrowane na laboratorium).
\item[XSS] Atak Cross-Site Scripting polega na wysłaniu w zapytaniu kodu napisanego w języku Javascript. Jest to atak na przeglądarkę, a nie na serwer jak w przypadku ataków typu Injection.
\item[Błędy uwierzytelniania i sesji] Szczególnie wrażliwy jest moment ustalenia tożsamości użytkownika. W przypadku aplikacji internetowych, które pracują w środowisku bezstanowym, konieczna jest także staranna ochrona sesji. Bowiem przechwycenie sesji jest równoważne z przełamaniem uwierzytelnienia.
\end{description}
\end{solution}

\question Omów niebezpieczeństwa związane z bezstanowością protokołu HTTP.
\begin{solution}
Protokół HTTP jest bezstanowy, co oznacza, że w wersji podstawowej każde zapytanie jest oddzielnym połączeniem. Rozwiązanie to ma sporo zalet związanych z wydajnością komunikacji, jednak cierpi na problemy utrzymywania spójności sesji. W przypadku aplikacji internetowych wymagających kontroli dostępu serwer musi być przekonanym, że seria zapytań jest przesyłana od konkretnego wcześniej uwierzytelnionego klienta. Identyfikator sesji jest przyznawany przez serwer przy pierwszym połączeniu, a później przesyłany przez klienta przy każdym z kolejnych zapytań. Wykradzenie identyfikatora sesji jest najczęściej równoznaczne z przechwyceniem sesji i przejęciem uprawnień klienta. 
\end{solution}

\question Na czym polega atak XSRF?
\begin{solution}
Atak Cross-Site Request Forgery (XSRF) dotyczy nadużycia poprawnie otwartej sesji. W typowym schemacie atakujący przesyła użytkownikowi adres URL, który odnosi się do innego systemu. Kliknięcie jest widoczne jako poprawna akcja w ramach otwartej sesji. Problem polega na tym, że przeglądarka ma centralny rejestr plików cookie (najczęściej przechowujących identyfikatory sesji), a więc nie może określić, która zakładka ma prawo do korzystania z sesji. 
\end{solution}

\question W jaki sposób bronić się przed atakiem XSRF?
\begin{solution}
XSRF jest atakiem na sesję, a więc należy uszczelnić mechanizmy kontroli jej spójności. Najlepiej jest to zrobić poprzez wprowadzenie dodatkowego mechanizmu losowych, każdorazowo zmiennych jednorazowych kluczy sesji, które są przekazywane w każdym zapytaniu. Możliwe jest także sprawdzanie, źródła zapytania poprzez pole nagłówka HTTP Referer. Dobrą strategią jest także wymaganie dodatkowego uwierzytelnienia przy szczególnie istotnych operacjach. 
\end{solution}


\question Przedstaw podstawowe metody przed atakiem XSS?
\begin{solution}
Atak XSS (Cross-Site Scripting) polega na umieszczeniu na stronie internetowej złośliwego kodu Javascript. Niezależnie od zastosowanej przez atakującego metody, jedyną skuteczną metodą jest walidacja wszystkich danych wejściowych do systemu. Precyzyjne określenie dopuszczalnych formatów i kontrola wszystkich danych pod kątem zgodności z nimi eliminuje podatność na XSS.  
\end{solution}

\question Przedstaw metody obrony przed atakami typu Injection?
\begin{solution}
Ataki typu Injection dotyczą aplikacji internetowych. Polegają ,,wstrzyknięciu'' spreparowanych danych wejściowych do serwera tak, aby ten wykonał niezamierzone przez programistę operacje. 
Obrona przed tego typu atakami polega na sprawdzaniu danych wejściowych przed wykorzystaniem tych danych w programie. Istotna jest również separacja uprawnień, tak aby nawet jeżeli dojdzie do wykonywania złośliwych poleceń, skutki były ograniczone.
\end{solution}

\question Omów przykład błędu skutkującemu możliwością SQL-Injection?
\begin{solution}
Atak SQL-Injection jest możliwy w przypadku gdy dane otrzymane od użytkownika nie będą należycie sprawdzone przed wykorzystaniem ich w zapytaniach do bazy danych.\\
Przykładowy kod w PHP:\\
\$catid = mysql\_real\_escape\_string( \$\_GET[\lq catid\lq ] );\\
\$query = \lq\lq SELECT header, shorttext FROM news WHERE id = \lq\lq.\$catid.\lq\lq\ ORDER BY id DESC LIMIT 10\lq\lq;\\
W powyższym zapytaniu zmienna \$catid umieszczana jest w zapytaniu SQL jako liczba (nie jest pomiędzy cudzysłowami jak typ string). Niebyłoby w tym nic złego gdyby do zapytania trafiały jedynie dane uprzednio właściwie zweryfikowane np. używając funkcji is\_numeric() która sprawdzi czy otrzymany ciąg znaków jest liczbą. Funkcja której użyto do zabezpieczenia danych pochodzących od użytkownika to mysql\_real\_escape\_string(), która dodaje lewe ukośniki przed następującymi znakami: \textbackslash x00, \textbackslash n, \textbackslash r, \textbackslash, \lq, \lq\lq oraz \textbackslash x1a. Taka ochrona sprawdza się świetnie, gdy mamy do czynienia z danymi typu string, które są umieszczane w cudzysłowach. W tym przykładzie jednak w zapytaniu do bazy dane wejściowe są  innego typu. Powyższe zapytanie ma na celu pobrać z bazy danych nagłówki i skróconą wersję dziesięciu ostatnich artykułów przypisanych do kategorii \$catid. Powyższy sposób implementacji tego zadania zawiera jednak błąd skutkujący możliwością SQL-Injection.\\
Przykładowe wykorzystanie błędu:\\
Użytkownik przesyła do serwisu parametr catid metodą GET z wartością:\\
NULL UNION ALL SELECT username, password FROM users \# \\
Zapytanie do bazy danych przybiera postać:\\
SELECT header, shorttext FROM news WHERE id = NULL UNION ALL SELECT username, password FROM users \# ORDER BY id\\
A jego wykonanie zwróci z tabeli users nazwy użytkowników wraz z hasłem.
\end{solution}

\question Przedstaw metody obrony przed atakami typu Phishing?


\end{questions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Kontrola dostępu}
\begin{questions}

\question Omów wybraną metodę przechowywania uprawnień w systemie.
\begin{solution}
Przedstawmy macierz uprawnień (ang. ACM - Access Control Matrix). Wiersze tej macierzy stanowią podmioty (użytkownicy systemu), a kolumny to obiekty (zasoby systemu). Na przecięciu odpowiedniego wiersza i kolumny zapisane są prawa jakie dany podmiot ma do danego obiektu. Model ten został po raz pierwszy opisany przez Lampsona w 1971r.
\end{solution}

\question Wyjaśnij dlaczego model MAC jest trudny w implementacji.
\begin{solution}
MAC (ang. Mandatory Access Control) to model obowiązkowej kontroli dostępu. Zakłada on, że każdy z obiektów w systemie (pliki, urządzenia, itp) ma przydzieloną etykietę definiującą poziom poufności/bezpieczeństwa. Główną trudnością w MAC jest to, że system musi kontrolować wszystkie operacje pod względem etykiet poufności. W ten sposób może zablokować każde działanie, które mogłoby obniżyć poufność obiektu. W przypadku dużych systemów informatycznych (np. system operacyjny) uporządkowanie ilość obiektów i dopuszczalnych operacji na nich stanowi spore wyzwanie.
\end{solution}

\question Na czym polega model DAC.
\begin{solution}
DAC (ang. Discretionary Access Control) to model uznaniowej kontroli dostępu. Użytkownicy w tym modelu mogą dosyć swobodnie zarządzać posiadanymi uprawnieniami od wszelkiego typu zasobów. Według swojego uznania mogą przekazywać uprawnienia innym użytkownikom, czy procesom. W DAC nie ma centralnych mechanizmów gwarantujących poziom ochrony dla danych.
\end{solution}

\question Omów model RBAC.
\begin{solution}
RBAC to model kontroli dostępu oparty na rolach (ang. Role Based Access Control). Uprawnienia nie są nadawane bezpośrednio użytkownikom systemu, ale poprzez role. Dopiero nominowanie użytkownika do danej roli daje mu odpowiednie uprawnienia. Dzięki temu zarządzanie uprawnieniami jest ułatwione, a system zachowuje elastyczność, gdyż użytkownik może posiadać wiele ról, z których każda może mieć niezależne uprawnienia. 
\end{solution}

\question Na czym polega przechowywanie oprawnień w formie ACL?
\begin{solution}
ACL (ang. Access Control List) jest techniką przechowywania uprawnień w systemie. Polega ona na tym, że do każdego obiektu (zasobu) przypisana jest lista par (podmiot, uprawnienie). W momencie prośby o dostęp do zasobu system weryfikuje, czy podmiot proszący i wnioskowane uprawnienie są na liście ACL związanej z danym obiektem. Technika ta jest wydajna w przypadku gdy obiektów jest znacznie więcej niż użytkowników.
\end{solution}

\question Przedstaw model ochrony Take-Grant.
\begin{solution}
\fixit
Model ten oparty jest na grafie, w którym wierzchołki stanowią obiekty i podmioty, zaś etykietowane połączenia między nimi opisują uprawnienia.

Model ochrony Take-Grant składa się z: zbioru podmiotów S, zbioru obiektów O, zbioru praw dostępu R. System ochrony jest modelowany za pomocą grafu, w którym każdy obiekt bądź podmiot jest wierzchołkiem grafu, a prawa określonego podmiotu do pewnego obiektu są modelowane za pomocą etykietowanej i skierowanej od podmiotu do obiektu krawędzi. Cztery elementarne operacje w modelu to:
\begin{itemize}
\item create(o,r) – dodaje nowy wierzchołek do grafu. Z s do o jest tworzony łuk z etykietą r opisująca prawo s do o.
\item revoke(o,r) – s usuwa prawo d do obiektu o. Łuk z s do o jest etykietowany jako q\r, gdzie q jest zbiorem uprawnień.
\item grant(o, p, r) – podmiot s przyznaje o prawo dostępu r do p. W grafie dodawany jest łuk z o do p etykietowany jako r.
\item take(o,p,r) -  podmiot s zabiera o prawo dostępu r do p. W grafie dodawany jest łuk z o do p etykietowany jako r.
\end{itemize}
Użyteczność modelu Take-Grant polega na tym, że identyfikuje warunki, na jakich użytkownik może otrzymywać dostęp do obiektu.

\end{solution}

\question Przedstaw schemat ,,High-water mark'' do ustalania poziomu poufności.
\begin{solution}
Strategia ,,High-water mark'' dotyczy przyznawania etykiet poufności w systemach chronionych modelem MAC. Według tej strategii dokument dostaje najwyższą etykietę ze wszystkich zasobów, które zostały wykorzystane do jego stworzenia.
\end{solution}


\end{questions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Bezpieczna administracja}
\begin{questions}

\question Przedstaw podstawowe zasady etyki hackowania.
\begin{solution}
Skuteczna obrona wymaga także znajomości technik ataków. Hackowanie jest właśnie takim kontrolowanym atakowaniem systemu, szukaniem słabości i potencjalnych zagrożeń. Różnica pomiędzy hackowaniem a atakowaniem jest więc bardzo delikatna, dlatego też hackując systemy należy dbać o etykę tych działań, a w szczególności:
\begin{itemize}
\item nie powodować żadnych zniszczeń lub strat,
\item znalezione słabości niezwłocznie zgłosić do operatora systemu,
\item najlepiej uzyskać wcześniejszą zgodę operatora.
\end{itemize}
\end{solution}

\question Przedstaw czym kopie zapasowe różnią się od systemu archiwizacji.
\begin{solution}
\fixit
W języku polskim określenia: „backup” i „archiwizacja danych” są (często mylnie) stosowane zamiennie. Jednak w języku angielskim „backup” i „data archiving” określają różne działania. Podobnie w języku polskim kopia bezpieczeństwa i archiwizacja danych. „Backup” dotyczy tworzenia kopii bezpieczeństwa danych w celu ich odtworzenia po utracie lub uszkodzeniu, natomiast „data archiving” oznacza proces tzw. warstwowania danych, czyli ich dzielenia na dane aktywne, nieaktywne i referencyjne, a następnie zapisywania w odpowiednich obszarach zapisu. D
\end{solution}

\question Wyjaśnij czy kopie zapasowe zapewniają wysoką dostępność danych?
\begin{solution}
Zadaniem klasycznych systemów kopii zapasowych jest zabezpieczenie przed utratą danych. Nie zapewniają jednak one wysokiej dostępności (ang. high availability), czyli szybkiego i pewnego dostępu do danych. Stawiając pytanie w drugą stronę można stwierdzić, że systemy wysokiej dostępności muszą realizować mechanizmy kopii zapasowych.
\end{solution}

\question Wyjaśnij czym różni się kopia zapasowa pełna, przyrostowa i różnicowa.
\begin{solution}
\begin{description}
\item[Kopia pełna], zawsze musi być wykonana na początku. Tworzymy pełny obraz archiwizowanych plików bez względu na to, czy od wykonania ostatniego obrazu w plikach zaszły jakieś zmiany. Największy rozmiar i najdłuższy czas wykonywania.
\item[Kopia przyrostowa] charakteryzuje się tym, że do jej przywrócenia potrzebna jest najświeższa kopia pełna oraz wszystkie następujące po niej kopie przyrostowe. Backup polega archiwizowaniu tylko tej części, która ,,przyrosła'', co automatycznie zmniejsza jego czas i wielkość w porównaniu do kopii pełnej.
\item[Kopia różnicowa] podobnie jak w przypadku kopii przyrostowej potrzebujemy obrazu bazowego (pełnego) na podstawie którego określane będą różnice w plikach. Archiwizowane są tylko te pliki, które zostały utworzone lub zmodyfikowane od momentu wykonania ostatniej pełnej kopii.
\end{description}
\end{solution}

\question Wyjaśnij terminy DDOS, DMZ, Firewall, IDS, IPS, DLP, DPI.
\begin{solution}
\fixit (za dużo Wikipedii)
\begin{description}
\item[DDOS] (ang. Distributed Denial of Service – rozproszona odmowa usługi) – atak na system komputerowy lub usługę sieciową w celu uniemożliwienia działania poprzez zajęcie wszystkich wolnych zasobów, przeprowadzany równocześnie z wielu komputerów
\item[DMZ]
Demilitarized zone (DMZ), strefa zdemilitaryzowana bądź ograniczonego zaufania – jest to wydzielany na zaporze sieciowej (ang. firewall) obszar sieci komputerowej nienależący ani do sieci wewnętrznej (tj. tej chronionej przez zaporę), ani do sieci zewnętrznej (tej przed zaporą; na ogół jest to Internet). W strefie zdemilitaryzowanej umieszczane są serwery "zwiększonego ryzyka włamania", przede wszystkim serwery świadczące usługi użytkownikom sieci zewnętrznej, którym ze względów bezpieczeństwa nie umożliwia się dostępu do sieci wewnętrznej (najczęściej są to serwery WWW i FTP). W strefie zdemilitaryzowanej umieszczane są także te serwery usług świadczonych użytkownikom sieci wewnętrznej, które muszą kontaktować się z obszarem sieci zewnętrznej (serwery DNS, proxy, poczty i inne), oraz serwery monitorujące i reagujące na próby włamań IDS.
\item[Firewall]
Zapora sieciowa (ang. firewall – ściana przeciwogniowa) – jeden ze sposobów zabezpieczania sieci i systemów przed intruzami.
Termin ten może odnosić się zarówno do dedykowanego sprzętu komputerowego wraz ze specjalnym oprogramowaniem, jak i do samego oprogramowania blokującego niepowołany dostęp do komputera, na którego straży stoi. Pełni rolę połączenia ochrony sprzętowej i programowej sieci wewnętrznej LAN przed dostępem z zewnątrz tzn. sieci publicznych, Internetu, chroni też przed nieuprawnionym wypływem danych z sieci lokalnej na zewnątrz. Często jest to komputer wyposażony w system operacyjny z odpowiednim oprogramowaniem. Do jego podstawowych zadań należy filtrowanie połączeń wchodzących i wychodzących oraz tym samym odmawianie żądań dostępu uznanych za niebezpieczne.
\item[IDS]
(ang. intrusion detection system) Ogólna nazwa systemów wykrywających intruzów. Warto je stosować, bo umożliwiają wykrywanie włamań i nieuprawnionych działań wewnątrz sieci - kiedy atakującymi są np. pracownicy - ale umożliwiają też wykrycie ataków z zewnątrz, np. DoS. 
Istnieją zasadniczo dwa rodzaje systemów IDS oraz trzeci, będący ich syntezą:
\begin{itemize}
\item{HIDS - Host IDS} Działa lokalnie, na wybranym hoście - może to być np. serwer bazodanowy. Odpowiednie informacje są zbierane z logów systemowych i aplikacyjnych i przesyłane na serwer, który je analizuje. Jeżeli jakiś użytkownik wykonał niedozwoloną czynność (np. nieautoryzowana modyfikacja pliku), informacja o tym szybko trafia do takiego serwera, który może podjąć adekwatne działanie.
Wady? Przy dużych sieciach taki system staje się niewygodny w obsłudze i nieefektywny. Poza tym odcięcie lub awaria serwera HIDS wyłącza cały system zabezpieczający.
\item{NIDS - Network IDS} Ten wariant systemu IDS działa w obrębie sieci, analizując przesyłane przez nią pakiety i określając je jako prawidłowe lub złośliwe. Zaletą NIDS jest to, że dobrze radzi sobie z wykrywaniem ataków spoza sieci, również DoS.
Słabości? Takie systemy nie przeanalizują ruchu szyfrowanego, zaś przy dużym obciążeniu sieci mogą - żeby uniknąć wprowadzenia wąskiego gardła - analizować przesyłane pakiety bardzo pobieżnie.
\end{itemize}
\item[IPS]
Intrusion prevention system
\item[DLP]
Ochrona przed wyciekami informacji (ang. DLP – Data Leak/Leakage/Loss Protection/Prevention) – ogólna nazwa technologii informatycznych wspomagających ochronę danych w postaci elektronicznej przed kradzieżą lub przypadkowymi wyciekami.
Systemy DLP wdraża się w organizacjach przetwarzających informacje podlegające ochronie z powodów biznesowych (tajemnica przedsiębiorstwa) lub prawnych (osobowe, dane wrażliwe, finansowe, zdrowotne) a których ujawnienie może narazić organizację na odpowiedzialność karną, cywilną lub innego rodzaju straty. Wdrożenia DLP służą najczęściej realizacji prawnych lub branżowych wymogów ochrony danych osobowych i finansowych (PCI DSS).
\item[DPI]
Głęboka Inspekcja Pakietów (często używany skrót DPI od ang. Deep Packet Inspection) – technika sieciowa pozwalająca ISP analizować pakiety przesyłane przez sieć pod względem ich treści. W zależności od zawartości pakiet jest zatrzymywany, opóźniany, zmieniany, lub przesyłany dodatkowo w celu zapisania. Możliwe jest składanie wielu pakietów w jedną całość i analizowanie ich razem.
\end{description}
\end{solution}
\end{questions}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Zarządzanie bezpieczeństwem}

\begin{questions}

\question Omów krótko kwestię ekonomicznego doboru zabezpieczeń.
\begin{solution}
Planując zabezpieczenia systemu informatycznego należy mieć przed oczami wartość chronionych zasobów. Z ekonomicznego punktu widzenia równie błędny jest niedostateczny poziom zabezpieczeń, jak i nadmiernie wysoki ich poziom. Do ilustracji tego faktu można posłużyć się krzywą kosztu zabezpieczeń i krzywą potencjalnych strat. Miejsce ich przecięcia pokazuje optymalne zabezpieczenia dla konkretnego przypadku. 
\end{solution}

\question Wyjaśnij znaczenie testów penetracyjnych.
\begin{solution}
Testy penetracyjne to rodzaj zewnętrznego audytu przypominającego pod wieloma aspektami realny atak. Osoby przeprowadzające test penetracyjny działają jak atakujący. Korzystają z puli możliwych ataków (technicznych, organizacyjnych, socjotechnicznych), żeby uzyskać niedozwolony dostęp do systemu. Przeprowadzanie testów penetracyjnych jest wyjątkowo trudnym zadaniem, albowiem atakujący musi działać niestandardowo, a jednocześnie w pełni kontrolować wszystkie swoje działania, tak, żeby nie doprowadzić do uszkodzeń w systemie, albo niekontrolowanych wycieków informacji.
\end{solution}

\question Wyjaśnij znaczenie dokumentu polityki bezpieczeństwa.
\begin{solution}
Dokument polityki bezpieczeństwa jest podstawową ochrony zasobów informatycznych organizacji. Zawiera on opis zasobów sklasyfikowanych według poziomu poufności/ważności, stosowanych metod oraz procedur ochrony, a także zakresy odpowiedzialności poszczególnych pracowników. 
Jeżeli organizacja nie opracowała polityki bezpieczeństwa, to najczęściej oznacza, że ochrona jest chaotyczna i nieprzemyślana, a tym samym nie będzie skuteczna.
\end{solution}


\question Wyjaśnij dlaczego ewidencja i klasyfikacja zasobów informatycznych jest podstawą budowania efektywnego systemu ochrony.
\begin{solution}
Pełna informacja o posiadanych zasobów informatycznych oraz ich analiza pod względem krytyczności dla działania organizacji, są niezbędne do uzasadnionego doboru poziomu ochrony oraz związanego z nim odpowiednimi środkami technicznymi. 

\fixit
Ewidencja pozwala na bieżąco utrzymywać porządek w zasobach infrastruktury. Każdy element objęty ewidencją powinien być oznaczony, w taki sposób, aby można było jednoznacznie stwierdzić, czy sprzęt lub oprogramowanie znajdują się we właściwym miejscu. Często zdarza się, że firmy zaniedbują ten aspekt i inwentaryzacja jest wykonywana na potrzeby księgowości i ewidencji środków trwałych, przez co poświęca się jednorazowo mnóstwo czasu. Dedykowane oprogramowanie przyspiesza ten proces, aby czynności takie jak aktualizacja oprogramowania nie stanowiły szczególnego problemu. Jest to istotne zwłaszcza w przypadku krytycznych poprawek, gdzie ujawniona luka bezpieczeństwa może stać się źródłem kosztownych strat. Panowanie nad zasobami uszczelnia system ochrony, ponieważ pozwala na szybkie reagowanie w przypadku wykrycia problemów.
\end{solution}

\question Na czym polega audyt polityki bezpieczeństwa?
\begin{solution}
Audyt dokumentu polityki bezpieczeństwa polega na zweryfikowaniu jej zgodności ze stosowanymi zabezpieczeniami. Wymagane są ciągłe modyfikacje odzwierciedlające zmieniające się uwarunkowania pracy firmy, profilu działania, stosowanego sprzetu i oprogramowania. Zakończony audyt polityki bezpieczeństwa powinien wskazać braki i nieścisłości we wdrożonej dokumentacji, sposób uzupełnienia braków i poprawienia nieścisłości. Audyt powinien również zweryfikować poprawność wdrożenia dokumentacji w organizacji oraz pomóc w postępowaniu naprawczym. Audyt polityki bezpieczeństwa powinien być wykonywany regularnie co jakiś czas.

\fixit
Audyt polityki bezpieczeństwa polega m.in. na: wskazaniu braków i nieścisłości we wdrożonej dokumentacji, wskazaniu sposobu uzupełnienia braków i poprawienia nieścisłości, zweryfikowaniu poprawności wdrożenia dokumentacji w organizacji oraz pomocy w postępowaniu naprawczym. Audyt ma na celu zweryfikowanie zastosowanej już polityki bezpieczeństwa oraz procedur z nią związanych, jak również wskazanie możliwych ulepszeń. Powinien być przeprowadzany w regularnych odstępach czasu, a nie tylko w przypadku naruszenia zabezpieczeń czy też istotnych zmian w konfiguracji i zasobach teleinformatycznych. Częstość audytu jest w dużej mierze kwestią umowną i zależy od specyfiki instytucji.
\end{solution}

\question Czego dotyczą normy z serii ISO 27000?
\begin{solution}
Seria norm ISO 27000 dotyczy szerokopojętego bezpieczeństwa systemów informatycznych. W obszarze jej zainteresowań pojawiają się zarówno nowe aspekty techniczne  - np. chmury obliczeniowe, jak i nowe szczegółowe wymagania dla określonych dziedzin wiedzy (np. służba zdrowia, telekomunikacja czy kryminalistyka). Zakres danych przetwarzanych przez instytucje państwowe, firmy, jak i osóby prywatne staje się coraz większy. W związku z tym rośnie też problem zagrożeń z tym związanych. 
\end{solution}


\question Czego dotyczy norma PN-ISO 17799?
\begin{solution}
Norma ISO 17799 wywodzi się z brytyjskiego standardu bezpieczeństwa BS 7799. Stanowi zestaw wskazówek dla wdrożenia i utrzymania bezpieczeństwa informacji w przedsiębiorstwie.

\fixit
Norma PN-ISO/IEC 17799:2007 jest polskim odpowiednikiem normy ISO/IEC 17799:2005.

Określa ona wytyczne związane z ustanowieniem, wdrożeniem, eksploatacją, monitorowaniem, przeglądem, utrzymaniem i doskonaleniem Systemu Zarządzania Bezpieczeństwem Informacji. Stanowi ona uzupełnienie normy PN-ISO/IEC 27001:2007. Zawiera zalecenia i ogólne zasady dotyczące inicjowania działań, wdrażania, utrzymania i doskonalenia zarządzania bezpieczeństwem informacji w organizacji. Cele stosowania zabezpieczeń przedstawione w normie są powszechnie akceptowanymi praktykami zarządzania bezpieczeństwem informacji. Norma wycofana i zastąpiona przez PN-ISO/IEC 27002:2014-12.

\end{solution}

\question Jakie dane chronione są przez ustawę o ochronie danych osobowych?
\begin{solution}
W rozumieniu ustawy za dane osobowe uważa się wszelkie informacje dotyczące zidentyfikowanej lub możliwej do zidentyfikowania żyjącej osoby fizycznej, np:
\begin{itemize}
\item Imię, nazwisko
\item Adres
\item PESEL
\item DNA, linie papilarne
\end{itemize}

Szczególnie chronione są tzw. dane wrażliwe do których zaliczamy:
\begin{itemize}
\item pochodzenie rasowe lub etniczne
\item poglądy polityczne
\item przekonania religijne lub filozoficzne
\item przynależność wyznaniową, partyjną lub związkową
\item stan zdrowia, kodu genetycznego, nałogów lub życia seksualnego,
\item skazania, orzeczenia o ukaraniu i mandaty karnych, a także inne orzeczenia wydane w postępowaniu sądowym lub administracyjnym.
\end{itemize}

\fixit
W rozumieniu ustawy za dane osobowe uważa się wszelkie informacje dotyczące zidentyfikowanej lub możliwej do zidentyfikowania osoby fizycznej. Osobą możliwą do zidentyfikowania jest osoba, której tożsamość można określić bezpośrednio lub pośrednio, w szczególności przez powołanie się na numer identyfikacyjny albo jeden lub kilka specyficznych czynników określających jej cechy fizyczne, fizjologiczne, umysłowe, ekonomiczne, kulturowe lub społeczne. Informacji nie uważa się za umożliwiającą określenie tożsamości osoby, jeżeli wymagałoby to nadmiernych kosztów, czasu lub działań. Danymi osobowymi są nie tylko, imię czy nazwisko, ale również wszelkiego typu przypisane numery, określone cechy (np. fizjologiczne, umysłowe, ekonomiczne) itd. Danymi osobowymi nie będą zatem pojedyncze informacje o dużym stopniu ogólności, np. sama nazwa ulicy i numer domu czy wysokość wynagrodzenia. Informacja ta będzie jednak stanowić dane osobowe wówczas, gdy zostanie zestawiona z innymi, dodatkowymi informacjami, np. imieniem i nazwiskiem czy numerem PESEL, które w konsekwencji można odnieść do konkretnej osoby. Adres poczty elektronicznej – bez dodatkowych informacji, umożliwiających ustalenie tożsamości osoby – zasadniczo nie stanowi danych osobowych. Występujący samodzielnie adres poczty elektronicznej można w wyjątkowych przypadkach uznać za dane osobowe, ale tylko wtedy, gdy elementy jego treści pozwalają, bez nadmiernych kosztów, czasu lub działań – na ustalenie na ich podstawie tożsamości danej osoby. Dzieje się tak w sytuacji, gdy elementami treści adresu są np. imię i nazwisko jego właściciela.

\end{solution}


\question Jakie klauzule tajności przewiduje ustawa o ochronie informacji niejawnych?
\begin{solution}
Ustawa o ochronie informacji niejawnych określa zasady przetwarzania danych mogących mieć wpływ na bezpieczeństwo państwa. Autor dokumentu może nadać mu jeden z czterech poziomów tajności: ściśle tajne, tajne, poufne i zastrzeżone. Nadanie klauzuli tajności precyzyjnie określa metody przetwarzania, ochrony, a także grupę osób, które mogą mieć do niego dostęp. 
\end{solution}


\question Na czym polega test penetracyjny?
\begin{solution}
Test penetracyjny polega na praktycznym sprawdzeniu odporności systemu na atak. Może być on prowadzony z wnętrza badanej sieci, jak i z zewnątrz. Podczas realizacji takiego testu należy brać pod uwagę możliwość załamania systemu, toteż oczywiste staje się wykonywanie pełnych kopii zapasowych, aby ich brak nie determinował rezygnacji z niektórych działań. Test penetracyjny (Pentest) rozpoczyna się zwykle od fazy rozpoznania, która polega m. in. na skanowaniu, identyfikacji słabych punktów czy błędów implementacji. Po tej fazie następuje zasadnicza część - atak. Stanowi on próbę wykorzystania znalezionych słabości w celu uzyskania nieautoryzowanego dostępu do określonych zasobów, kompromitacji poufności czy uruchomienia exploitów. Ostatnią częścią testu penetracyjnego jest dostarczenie raportu obejmującego wykryte błędy, aby możliwe było uszczelnienie systemu przed rzeczywistym atakiem. Pentesty stanowią skuteczną metodą podnoszenia poziomu bezpieczeństwa i są niezastąpione w procesach zarządzania ryzykiem. 
\end{solution}

\end{questions}





\end{document}
